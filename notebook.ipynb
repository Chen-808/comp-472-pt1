{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP 472 - Mini Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all necessary libraries\n",
    "\n",
    "- gzip, json - Initial file parsing\n",
    "- nltk - Word tokenization\n",
    "- pandas - Data exploration\n",
    "- numpy - Math\n",
    "- matplotlib - Data exploration\n",
    "- gensim - Load in pre-trained word2vec models\n",
    "- sklearn - ML algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports \n",
    "import gzip\n",
    "import json\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.downloader as api\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Preparation & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will be extracting and reading the JSON file into a Pandas DataFrame. We decided to use `pd.read_json()` rather than `json.load()` since DataFrames give us a more pleasant data type to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read JSON file into Pandas DataFrame\n",
    "f = gzip.open('goemotions.json.gz', 'rb')\n",
    "df = pd.read_json(f)\n",
    "df.columns = ['comment', 'emotion', 'sentiment']\n",
    "\n",
    "# Close file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `DataFrame.head()` gives us a nice visual of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - Plotting data\n",
    "\n",
    "Here we will be using matplotlib to visualize and explore our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group sentiments by value and count\n",
    "sentiment = df.groupby(['sentiment'])['sentiment'].count()\n",
    "\n",
    "# Plot as pie chart\n",
    "plt.title('GoEmotions by Sentiment')\n",
    "plt.pie(sentiment, labels = sentiment.index, autopct = '%1.2f%%')\n",
    "\n",
    "plt.savefig('sentiments.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group emotions by value and count, sort descending\n",
    "emotion = df.groupby(['emotion'])['emotion'].count().sort_values(ascending=False)\n",
    "\n",
    "# Plot as bar graph\n",
    "plt.bar(emotion.index, emotion)\n",
    "plt.xticks(\n",
    "    rotation=90, \n",
    "    fontweight='light',\n",
    ")\n",
    "\n",
    "plt.title('GoEmotion by Emotion')\n",
    "plt.xlabel('Emotion')\n",
    "plt.ylabel('Number of Comments')\n",
    "\n",
    "plt.savefig('emotions.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Words as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "comment_vector = vectorizer.fit_transform(df['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = comment_vector.shape[1]\n",
    "print(\"Vocabulary size: \" + str(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(comment_vector, df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB()\n",
    "nb_model = nb_classifier.fit(X_train, y_train['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = vectorizer.transform(['Thank you!'])\n",
    "nb_model.predict(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Embeddings as Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Load word2vec model\n",
    "\n",
    "We will be downloading the `word2vec-google-news-300` model using Gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Tokenize data\n",
    "\n",
    "Install required NLTK data and tokenize sentences into individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment when running for the first time\n",
    "# nltk.download('popular')\n",
    "\n",
    "tokenized_comments = df['comment'].apply(nltk.word_tokenize)\n",
    "tokens = np.concatenate(tokenized_comments.to_numpy())\n",
    "unique_tokens_count = len(np.unique(tokens))\n",
    "print('Number of unique tokens in dataset: ' + str(unique_tokens_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Calculate sentence vector (by taking average of word vectors)\n",
    "\n",
    "Here I have created two functions. The first function calculates the average vector of a sentence by averaging its individual word vectors. The second function calls the first function for a collection of sentences and returns an array containing each average vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average of single sentence\n",
    "def get_avg_vector(sentence, model, vector_size):\n",
    "    words = [word for word in sentence if word in model]\n",
    "    if len(words) >= 1:\n",
    "        return np.mean(model[words], axis=0)\n",
    "    else:\n",
    "        return np.zeros(vector_size) # Set length of vector to 0 for all dimensions\n",
    "\n",
    "# Get averages of collection of sentences\n",
    "def get_avg_vectors(tokenized, model, vector_size):\n",
    "    avg_vectors = []\n",
    "    for comment in tokenized:\n",
    "        avg_vectors.append(get_avg_vector(comment, model, vector_size))\n",
    "    return avg_vectors\n",
    "\n",
    "# Get average vector\n",
    "avg_word2vec = get_avg_vectors(tokenized_comments, word2vec_model, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 - Compute and display overall hit rate\n",
    "\n",
    "The overall hit rate is calculated by counting the number of zero vectors and dividing it by the total amount of vectors in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_hit_rate(tokens, model):\n",
    "    count = 0\n",
    "    for token in tokens:\n",
    "        if token in model:\n",
    "            count += 1\n",
    "    return count / len(tokens)\n",
    "\n",
    "hit_rate = count_hit_rate(tokens, word2vec_model)\n",
    "print(\"Hit rate for dataset: \" + str(hit_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 - Train base MLP models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(avg_word2vec, df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_emotion = MLPClassifier(early_stopping=True)\n",
    "mlp_emotion.fit(X_train_w2v, y_train_w2v['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_sentiment = MLPClassifier(early_stopping=True)\n",
    "mlp_sentiment.fit(X_train_w2v, y_train_w2v['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 - Train \"Top\" MLP models\n",
    "\n",
    "For this question, we are allowed to choose whichever hyper-parameters we would like. I chose to try adding another hidden layer to see how it would affect our results compared to the base MLP models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_mlp_emotion = MLPClassifier(early_stopping=True, hidden_layer_sizes=(100, 100))\n",
    "top_mlp_emotion.fit(X_train_w2v, y_train_w2v['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_mlp_sentiment = MLPClassifier(early_stopping=True, hidden_layer_sizes=(100, 100))\n",
    "top_mlp_sentiment.fit(X_train_w2v, y_train_w2v['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 - Classification report\n",
    "\n",
    "Here we will simply be calling the `classification_report()` function and piping the output to a file called `performance.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_emotion = mlp_emotion.predict(X_test_w2v)\n",
    "y_pred_sentiment = mlp_sentiment.predict(X_test_w2v)\n",
    "y_pred_top_emotion = top_mlp_emotion.predict(X_test_w2v)\n",
    "y_pred_top_sentiment = top_mlp_sentiment.predict(X_test_w2v)\n",
    "\n",
    "with open('performance.txt', 'w') as f:\n",
    "    f.write('Base-MLP emotion classifier\\n\\n')\n",
    "    f.write(classification_report(y_pred_emotion, y_test_w2v['emotion']))\n",
    "    f.write('\\n\\n')\n",
    "\n",
    "    f.write('Base-MLP sentiment classifier\\n\\n')\n",
    "    f.write(classification_report(y_pred_sentiment, y_test_w2v['sentiment']))\n",
    "    f.write('\\n\\n')\n",
    "\n",
    "    f.write('Top-MLP emotion classifier\\n\\n')\n",
    "    f.write(classification_report(y_pred_top_emotion, y_test_w2v['emotion']))\n",
    "    f.write('\\n\\n')\n",
    "\n",
    "    f.write('Top-MLP sentiment classifier\\n\\n')\n",
    "    f.write(classification_report(y_pred_top_sentiment, y_test_w2v['sentiment']))\n",
    "    f.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 - Two other pretrained embedding models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load two pretrained models using gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "glove_twitter_model = api.load('glove-twitter-200')\n",
    "glove_wiki_model = api.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get average vectors with new model and split data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter\n",
    "avg_tw = get_avg_vectors(tokenized_comments, glove_twitter_model, 200)\n",
    "X_train_tw, X_test_tw, y_train_tw, y_test_tw = train_test_split(avg_tw, df, test_size=0.2)\n",
    "\n",
    "# Wiki\n",
    "avg_wiki = get_avg_vectors(tokenized_comments, glove_wiki_model, 300)\n",
    "X_train_wiki, X_test_wiki, y_train_wiki, y_test_wiki = train_test_split(avg_wiki, df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now train our models using the new embedding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_twitter_emotion = MLPClassifier(early_stopping=True)\n",
    "mlp_twitter_emotion.fit(X_train_tw, y_train_tw['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_twitter_sentiment = MLPClassifier(early_stopping=True)\n",
    "mlp_twitter_sentiment.fit(X_train_tw, y_train_tw['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_wiki_emotion = MLPClassifier(early_stopping=True)\n",
    "mlp_wiki_emotion.fit(X_train_wiki, y_train_wiki['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_wiki_sentiment = MLPClassifier(early_stopping=True)\n",
    "mlp_wiki_sentiment.fit(X_train_wiki, y_train_wiki['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict and send results to performance.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tw_emotion = mlp_twitter_emotion.predict(X_test_tw)\n",
    "y_pred_tw_sentiment = mlp_twitter_sentiment.predict(X_test_tw)\n",
    "y_pred_wiki_emotion = mlp_wiki_emotion.predict(X_test_wiki)\n",
    "y_pred_wiki_sentiment = mlp_wiki_sentiment.predict(X_test_wiki)\n",
    "\n",
    "with open('performance.txt', 'a') as f:\n",
    "    f.write('MLP emotion classifier: glove-twitter-200 embedding model\\n\\n')\n",
    "    f.write(classification_report(y_pred_tw_emotion, y_test_tw['emotion']))\n",
    "    f.write('\\n\\n')\n",
    "\n",
    "    f.write('MLP sentiment classifier: glove-twitter-200 embedding model\\n\\n')\n",
    "    f.write(classification_report(y_pred_tw_sentiment, y_test_tw['sentiment']))\n",
    "    f.write('\\n\\n')\n",
    "\n",
    "    f.write('MLP emotion classifier: glove-wiki-gigaword-300 embedding model\\n\\n')\n",
    "    f.write(classification_report(y_pred_wiki_emotion, y_test_wiki['emotion']))\n",
    "    f.write('\\n\\n')\n",
    "\n",
    "    f.write('MLP sentiment classifier: glove-wiki-gigaword-300 embedding model\\n\\n')\n",
    "    f.write(classification_report(y_pred_wiki_sentiment, y_test_wiki['sentiment']))\n",
    "    f.write('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "40373490c7673d06f4a43f8a8785636cc055897b683e6a5ffe207e45dab1f65c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
