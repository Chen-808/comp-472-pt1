{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP 472 - Mini Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all necessary libraries\n",
    "\n",
    "- gzip, json - Initial file parsing\n",
    "- nltk - Word tokenization\n",
    "- pandas - Data exploration\n",
    "- numpy - Math\n",
    "- matplotlib - Data exploration\n",
    "- gensim - Load in pre-trained word2vec models\n",
    "- sklearn - ML algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports \n",
    "import gzip\n",
    "import json\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.downloader as api\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Preparation & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will be extracting and reading the JSON file into a Pandas DataFrame. We decided to use `pd.read_json()` rather than `json.load()` since DataFrames give us a more pleasant data type to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read JSON file into Pandas DataFrame\n",
    "f = gzip.open('goemotions.json.gz', 'rb')\n",
    "df = pd.read_json(f)\n",
    "df.columns = ['comment', 'emotion', 'sentiment']\n",
    "\n",
    "# Close file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `DataFrame.head()` gives us a nice visual of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>emotion</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>sadness</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>love</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Right? Considering it’s such an important docu...</td>\n",
       "      <td>gratitude</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>He isn't as big, but he's still quite popular....</td>\n",
       "      <td>disapproval</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>That's crazy; I went to a super [RELIGION] hig...</td>\n",
       "      <td>amusement</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>that's adorable asf</td>\n",
       "      <td>amusement</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Sponge Blurb Pubs Quaw Haha GURR ha AAa!\" fin...</td>\n",
       "      <td>amusement</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I have, and now that you mention it, I think t...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment      emotion sentiment\n",
       "0                                    That game hurt.      sadness  negative\n",
       "1     You do right, if you don't care then fuck 'em!      neutral   neutral\n",
       "2                                 Man I love reddit.         love  positive\n",
       "3  [NAME] was nowhere near them, he was by the Fa...      neutral   neutral\n",
       "4  Right? Considering it’s such an important docu...    gratitude  positive\n",
       "5  He isn't as big, but he's still quite popular....  disapproval  negative\n",
       "6  That's crazy; I went to a super [RELIGION] hig...    amusement  positive\n",
       "7                                that's adorable asf    amusement  positive\n",
       "8  \"Sponge Blurb Pubs Quaw Haha GURR ha AAa!\" fin...    amusement  positive\n",
       "9  I have, and now that you mention it, I think t...      neutral   neutral"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - Plotting data\n",
    "\n",
    "Here we will be using matplotlib to visualize and explore our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Group sentiments by value and count\n",
    "sentiment = df.groupby(['sentiment'])['sentiment'].count()\n",
    "\n",
    "# Plot as pie chart\n",
    "plt.title('GoEmotions by Sentiment')\n",
    "plt.pie(sentiment, labels = sentiment.index, autopct = '%1.2f%%')\n",
    "\n",
    "plt.savefig('sentiments.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Group emotions by value and count, sort descending\n",
    "emotion = df.groupby(['emotion'])['emotion'].count().sort_values(ascending=False)\n",
    "\n",
    "# Plot as bar graph\n",
    "plt.bar(emotion.index, emotion)\n",
    "plt.xticks(\n",
    "    rotation=90, \n",
    "    fontweight='light',\n",
    ")\n",
    "\n",
    "plt.title('GoEmotion by Emotion')\n",
    "plt.xlabel('Emotion')\n",
    "plt.ylabel('Number of Comments')\n",
    "\n",
    "plt.savefig('emotions.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Words as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "comment_vector = vectorizer.fit_transform(df['comment'])\n",
    "print(type(comment_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 30449\n"
     ]
    }
   ],
   "source": [
    "vocab_size = comment_vector.shape[1]\n",
    "print(\"Vocabulary size: \" + str(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(comment_vector, df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_emotion_model = nb_classifier.fit(X_train, y_train['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gratitude'], dtype='<U14')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = vectorizer.transform(['Thank you!'])\n",
    "nb_emotion_model.predict(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive'], dtype='<U9')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sentiment classifier\n",
    "nb_sentiment_model = nb_classifier.fit(X_train, y_train['sentiment'])\n",
    "v = vectorizer.transform(['Thank you!'])\n",
    "nb_sentiment_model.predict(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive' 'neutral' 'neutral' ... 'positive' 'neutral' 'neutral']\n",
      "emotion score:  0.16095332324525666\n",
      "['positive' 'neutral' 'neutral' ... 'positive' 'neutral' 'neutral']\n",
      "sentiment score:  0.5458037481084856\n"
     ]
    }
   ],
   "source": [
    "print (nb_emotion_model.predict(X_test))\n",
    "print(\"emotion score: \", nb_emotion_model.score(X_test, y_test['emotion']))\n",
    "\n",
    "print (nb_sentiment_model.predict(X_test))\n",
    "print(\"sentiment score: \",nb_sentiment_model.score(X_test, y_test['sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Emotion classifier\n",
    "dtc_emotion_model = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "dtc_emotion_model.fit(X_train, y_train['emotion'])\n",
    "\n",
    "\n",
    "#predictEmotionFromDT = dtc_emotion_model.predict(x_test[0:5])\n",
    "#print(x_test[0:5])\n",
    "#print(predictEmotionFromDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sentiment classifier\n",
    "dtc_sentiment_model = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "dtc_sentiment_model.fit(X_train, y_train['sentiment'])\n",
    "#predictSentimentFromDT = dtc_sentiment_model.predict(x_test[0:5])\n",
    "#print(predictSentimentFromDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['joy' 'approval' 'neutral' ... 'love' 'neutral' 'neutral']\n",
      "emotion score:  0.35842742404842276\n",
      "['positive' 'positive' 'neutral' ... 'positive' 'neutral' 'neutral']\n",
      "sentiment score:  0.5456291467815155\n"
     ]
    }
   ],
   "source": [
    "print (dtc_emotion_model.predict(X_test))\n",
    "print(\"emotion score: \", dtc_emotion_model.score(X_test, y_test['emotion']))\n",
    "\n",
    "print (dtc_sentiment_model.predict(X_test))\n",
    "print(\"sentiment score: \",dtc_sentiment_model.score(X_test, y_test['sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layered Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(max_iter=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(max_iter=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(max_iter=50)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Multi-Layered Perceptron classifier for emotion classification\n",
    "mlpcClassifierEmotion = MLPClassifier(max_iter=50)\n",
    "mlpcClassifierEmotion.fit(X_train, y_train['emotion'])\n",
    "#may or may not converge - > think about why? \n",
    "\n",
    "# Multi-Layered Perceptron classifier for sentiment classification\n",
    "mlpcClassifierSentiment = MLPClassifier(max_iter=50)\n",
    "mlpcClassifierSentiment.fit(X_train, y_train['sentiment'])\n",
    "# mlpcClassifierEmotion.predict(x_test)\n",
    "# mlpcClassifierEmotion.score(x_test, y_test['emotion'])\n",
    "#may need to pay attention to warnings -> model hasnt been optimized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['joy' 'approval' 'neutral' ... 'love' 'neutral' 'neutral']\n",
      "emotion score:  0.38330811314165986\n",
      "['positive' 'positive' 'neutral' ... 'positive' 'neutral' 'neutral']\n",
      "sentiment score:  0.5549121173320917\n"
     ]
    }
   ],
   "source": [
    "print (mlpcClassifierEmotion.predict(X_test))\n",
    "print(\"emotion score: \", mlpcClassifierEmotion.score(X_test, y_test['emotion']))\n",
    "\n",
    "print (mlpcClassifierSentiment.predict(X_test))\n",
    "print(\"sentiment score: \",mlpcClassifierSentiment.score(X_test, y_test['sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator for emotion classification:  MultinomialNB(alpha=0.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator for sentiment classification:  MultinomialNB(alpha=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# parameters\n",
    "param = {'alpha': [0, 0.5, 1, 2]} #mention in analysis \n",
    "\n",
    "# Top Multinomial Naive bayes classifier for emotion classification\n",
    "topMNBEmotion = GridSearchCV(mnb, param)\n",
    "topMNBEmotion.fit(X_train, y_train['emotion'])\n",
    "print(\"best estimator for emotion classification: \", topMNBEmotion.best_estimator_)\n",
    "\n",
    "# Top Multinomial Naive bayes classifier for Sentiment classification\n",
    "topMNBSentiment = GridSearchCV(mnb, param)\n",
    "topMNBSentiment.fit(X_train, y_train['sentiment'])\n",
    "print(\"best estimator for sentiment classification: \", topMNBSentiment.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator for emotion classification:  DecisionTreeClassifier(max_depth=8, min_samples_split=5)\n",
      "best estimator for sentiment classification:  DecisionTreeClassifier(max_depth=8, min_samples_split=5)\n"
     ]
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "\n",
    "# parameters\n",
    "param = {'criterion': ['entropy', 'gini'], 'max_depth': [3, 8], 'min_samples_split': [3,5]}\n",
    "#if its less than 3, dont split \n",
    "#depth of 3, depth of 8\n",
    "# Top DT classifier for emotion classification\n",
    "topDTEmotion = GridSearchCV(dt, param)\n",
    "topDTEmotion.fit(X_train, y_train['emotion'])\n",
    "print(\"best estimator for emotion classification: \", topDTEmotion.best_estimator_)\n",
    "\n",
    "# Top DT classifier for Sentiment classification\n",
    "topDTSentiment = GridSearchCV(dt, param)\n",
    "topDTSentiment.fit(X_train, y_train['sentiment'])\n",
    "print(\"best estimator for sentiment classification: \", topDTSentiment.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "20 fits failed out of a total of 80.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 503, in _validate_hyperparameters\n",
      "    raise ValueError(\n",
      "ValueError: The activation 'sigmoid' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.405999   0.32470029\n",
      " 0.41296122 0.32161563 0.41213186 0.32092451 0.40983301 0.32092451\n",
      " 0.4058826  0.32795953 0.41100425 0.33000379]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator for emotion classification:  MLPClassifier(activation='tanh', hidden_layer_sizes=(10, 10, 10), max_iter=5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "20 fits failed out of a total of 80.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 503, in _validate_hyperparameters\n",
      "    raise ValueError(\n",
      "ValueError: The activation 'sigmoid' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.55400272 0.46003081\n",
      " 0.55434466 0.46607643 0.55638892 0.42663102 0.55582149 0.38649475\n",
      " 0.55037972 0.46782247 0.55016147 0.49028776]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator for sentiment classification:  MLPClassifier(hidden_layer_sizes=(30, 50), max_iter=5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier()\n",
    "\n",
    "# parameters\n",
    "param = {'activation': ['sigmoid', 'tanh', 'relu', 'identity'], 'hidden_layer_sizes': [(30, 50), (10, 10, 10)], 'solver': ['adam', 'sgd'], 'max_iter': [5]}\n",
    "\n",
    "# Top MLP classifier for emotion classification\n",
    "topMLPEmotion = GridSearchCV(mlp, param)\n",
    "topMLPEmotion.fit(X_train, y_train['emotion'])\n",
    "print(\"best estimator for emotion classification: \", topMLPEmotion.best_estimator_)\n",
    "\n",
    "# Top MLP classifier for Sentiment classification\n",
    "topMLPSentiment = GridSearchCV(mlp, param)\n",
    "topMLPSentiment.fit(X_train, y_train['sentiment'])\n",
    "print(\"best estimator for sentiment classification: \", topMLPSentiment.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "performanceFile = open(\"performance.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5022"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performanceFile.write(\"Multiomial Naive Bayes classifier for 'emotion'\\n\\n\")\n",
    "\n",
    "#Performance of emotion classifier\n",
    "nb_emotion_model_prediction = nb_emotion_model.predict(X_test)\n",
    "mnb_emotion_report = classification_report(y_test['emotion'], nb_emotion_model_prediction)\n",
    "performanceFile.write(mnb_emotion_report)\n",
    "#print(mnb_emotion_report)\n",
    "\n",
    "# Confusion matrix\n",
    "mnb_emotion_confusion_matrix = confusion_matrix(y_test['emotion'], nb_emotion_model_prediction)\n",
    "performanceFile.write(str(mnb_emotion_confusion_matrix))\n",
    "#print(mnb_emotion_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performanceFile.write(\"Multiomial Naive Bayes classifier for 'sentiment'\\n\\n\")\n",
    "\n",
    "#Performance of sentiment classifier\n",
    "nb_sentiment_model_prediction = nb_sentiment_model.predict(X_test)\n",
    "mnb_sentiment_report = classification_report(y_test['sentiment'], nb_sentiment_model_prediction)\n",
    "performanceFile.write(mnb_sentiment_report)\n",
    "#print(mnb_sentiment_report)\n",
    "# Confusion matrix\n",
    "mnb_sentiment_confusion_matrix = confusion_matrix(y_test['sentiment'], nb_sentiment_model_prediction)\n",
    "performanceFile.write(str(mnb_sentiment_confusion_matrix))\n",
    "#print(mnb_sentiment_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4060"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performanceFile.write(\"Decision Tree classifier for 'emotion'\\n\\n\")\n",
    "\n",
    "#Performance of emotion classifier\n",
    "\n",
    "DT_emotion_model_prediction = dtc_emotion_model.predict(X_test)\n",
    "DT_emotion_report = classification_report(y_test['emotion'], DT_emotion_model_prediction)\n",
    "performanceFile.write(DT_emotion_report)\n",
    "\n",
    "#Confusion matrix\n",
    "DT_emotion_confusion_matrix = confusion_matrix(y_test['emotion'], DT_emotion_model_prediction)\n",
    "performanceFile.write(str(DT_emotion_confusion_matrix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performanceFile.write(\"Decision Tree classifier for 'sentiment'\\n\\n\")\n",
    "\n",
    "#Performance of sentiment classifier\n",
    "\n",
    "DT_sentiment_model_prediction = dtc_sentiment_model.predict(X_test)\n",
    "DT_sentiment_report = classification_report(y_test['sentiment'], DT_sentiment_model_prediction)\n",
    "performanceFile.write(DT_sentiment_report)\n",
    "\n",
    "#Confusion matrix\n",
    "DT_sentiment_confusion_matrix = confusion_matrix(y_test['sentiment'], DT_sentiment_model_prediction)\n",
    "performanceFile.write(str(DT_sentiment_confusion_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-Layered Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.45      0.54      0.49      2059\n",
      "     amusement       0.48      0.52      0.50      1192\n",
      "         anger       0.29      0.28      0.29      1068\n",
      "     annoyance       0.17      0.19      0.18      1653\n",
      "      approval       0.23      0.18      0.20      2232\n",
      "        caring       0.26      0.23      0.24       694\n",
      "     confusion       0.24      0.24      0.24       939\n",
      "     curiosity       0.35      0.30      0.33      1171\n",
      "        desire       0.29      0.27      0.28       448\n",
      "disappointment       0.15      0.16      0.16       966\n",
      "   disapproval       0.23      0.25      0.24      1523\n",
      "       disgust       0.21      0.25      0.23       562\n",
      " embarrassment       0.19      0.16      0.17       296\n",
      "    excitement       0.25      0.20      0.22       598\n",
      "          fear       0.39      0.37      0.38       355\n",
      "     gratitude       0.72      0.75      0.73      1419\n",
      "         grief       0.12      0.15      0.13        84\n",
      "           joy       0.31      0.25      0.28       886\n",
      "          love       0.53      0.62      0.58      1007\n",
      "   nervousness       0.18      0.15      0.16       148\n",
      "       neutral       0.50      0.51      0.50     11185\n",
      "      optimism       0.31      0.31      0.31       853\n",
      "         pride       0.11      0.07      0.08       148\n",
      "   realization       0.14      0.13      0.13       934\n",
      "        relief       0.19      0.18      0.18       149\n",
      "       remorse       0.37      0.41      0.39       332\n",
      "       sadness       0.27      0.29      0.28       783\n",
      "      surprise       0.32      0.31      0.31       680\n",
      "\n",
      "      accuracy                           0.38     34364\n",
      "     macro avg       0.29      0.29      0.29     34364\n",
      "  weighted avg       0.38      0.38      0.38     34364\n",
      "\n",
      "[[1102   31    7   41  101   16   13   13    9    9   14    6    1   48\n",
      "     6   77    1   60   99    3  275   33   13   23    6    1   11   40]\n",
      " [  38  625    7   53   26    4   13   12    4   17   26   10    9   18\n",
      "     2    8    1   53   14    1  199    8    0   16    2    8    7   11]\n",
      " [  21   15  302  167   24   15   18   13    5   38   64   54    6   11\n",
      "     6    2    2    4    8    1  244    3    1   16    1    2   15   10]\n",
      " [  34   55  140  310   59   19   36   36    6   69  113   84   24    8\n",
      "    15   18    6   13    9    5  462   20    1   32    2   15   36   26]\n",
      " [ 146   40   32   92  406   49   32   25   34   50   93   21    9   18\n",
      "     9   30    6   30   47    5  843   58    7   72   18   12   28   20]\n",
      " [  28   10   11   28   29  157    6    5    6   18   19    3    5    2\n",
      "     8   26    5   21   13    6  213   32    3   10    3   10   15    2]\n",
      " [  20   12   14   46   35    1  221  112    4   22   45    9    3    8\n",
      "     6    3    1    3    9    3  306    8    0   22    1    4    6   15]\n",
      " [  32   13   23   40   24    5  101  357    8   19   26    7    7   17\n",
      "     3    6    0    6   14    0  385    7    0   22    0    5   11   33]\n",
      " [  16    6    7   17   26   12    3    3  120   11   10    6    1    2\n",
      "     2   11    2    8   12    2  130   28    0    5    0    4    4    0]\n",
      " [  14   12   27   83   28    8   19   12   15  156   85   31   10    4\n",
      "    12   13    1    3    9    8  272   15    6   27    4   10   69   13]\n",
      " [  21   25   47  138   57   25   27   22   13   60  382   33   21    3\n",
      "    12    8    4    8   11    5  467   20    1   49    2    8   42   12]\n",
      " [  13   13   41   75   18    3    7    3    1   35   28  140   10    1\n",
      "    12    3    4    0    4    1  108    5    1    5    0    5   20    6]\n",
      " [   5    4   13   29    6    4    6    7    1   15   17   17   47    2\n",
      "     5    2    2    1    2    1   75    5    2    6    0    3   11    8]\n",
      " [  57   27    6   26   26    4    5   17    8   10    5    4    0  118\n",
      "     0   15    0   34   16    1  149   19    3   11    2    1    7   27]\n",
      " [   8    8    8   19    9    5    7    6    1   20    9   13    2    0\n",
      "   130    1    3    2    0   10   63    3    0    9    0    1   11    7]\n",
      " [  96    6    5    7   20   10    3    5    2    9    7    0    0   14\n",
      "     0 1070    1   32    4    0   68   24    4    2    6   17    5    2]\n",
      " [   3    0    2    0    2    0    2    1    1    4    2    2    0    0\n",
      "     4    2   13    0    2    0   22    3    1    0    0    4   13    1]\n",
      " [  94  107    7   17   41   10    4    6   10   11   14    2    2   31\n",
      "     3   33    0  221   67    0  137   18    3   11   12    0   10   15]\n",
      " [  90   19    8    7   23    4    5    7    2    9    7    1    1   11\n",
      "     0    8    2   37  627    0  114    7    2    5    3    3    3    2]\n",
      " [   2    0    3    5   12    9    3    5    0    9    7    5    0    1\n",
      "     8    0    1    0    1   22   32    1    0    3    1    4   12    2]\n",
      " [ 426  233  257  509  582  186  306  301  109  274  516  156   55  107\n",
      "    70   92   26  128  166   29 5661  221   30  323   41   53  177  151]\n",
      " [  50   10    8   20   50   30   10    8   43   11   26    1    1   13\n",
      "     6   19    2   13   10    2  209  263    3   16    5    5    9   10]\n",
      " [  21    3    2    5   11    2    3    0    0    1    3    2    1    6\n",
      "     2    4    0    8    2    0   50    6   10    5    0    0    1    0]\n",
      " [  34   18   25   49   76   10   22   12    8   25   54   12    8    9\n",
      "     3    7    3    8   12    5  330   22    1  118    6   12   17   28]\n",
      " [  14    1    1    2   11    5    1    1    1    4    2    0    0    1\n",
      "     0    8    1   14    3    0   40    6    1    1   27    0    3    1]\n",
      " [   4    3    1    8    3    3    6    1    3   14    7    5    7    0\n",
      "     2   16    5    2    3    0   39    6    0    7    0  135   51    1]\n",
      " [   7    4   13   32   24   14    7    2    1   70   32   17   11    1\n",
      "    10    8   17    7    5    7  203    4    1   11    2   45  224    4]\n",
      " [  39    9   15   35   27    4   22   24    1   19   23   12    4   24\n",
      "     1    5    0    2    3    2  170    2    1   22    1    2    3  208]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.39      0.42      0.40      3724\n",
      "    negative       0.54      0.53      0.54      7770\n",
      "     neutral       0.51      0.50      0.50     11185\n",
      "    positive       0.66      0.67      0.67     11685\n",
      "\n",
      "    accuracy                           0.55     34364\n",
      "   macro avg       0.53      0.53      0.53     34364\n",
      "weighted avg       0.55      0.55      0.55     34364\n",
      "\n",
      "[[1551  525 1063  585]\n",
      " [ 619 4093 2008 1050]\n",
      " [1244 1915 5552 2474]\n",
      " [ 577  991 2244 7873]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performanceFile.write(\"Multi-layered Perceptron classifier for 'emotion'\\n\\n\")\n",
    "\n",
    "#Performance of emotion classifier\n",
    "print(classification_report(y_test['emotion'], mlpcClassifierEmotion.predict(X_test)))\n",
    "performanceFile.write(classification_report(y_test['emotion'], mlpcClassifierEmotion.predict(X_test)))\n",
    "\n",
    "#Confusion matrix\n",
    "print(confusion_matrix(y_test['emotion'], mlpcClassifierEmotion.predict(X_test)))\n",
    "performanceFile.write(str(confusion_matrix(y_test['emotion'], mlpcClassifierEmotion.predict(X_test))))\n",
    "\n",
    "performanceFile.write(\"\\n\\nMulti-layered Perceptron classifier for 'sentiment'\\n\\n\")\n",
    "\n",
    "#Performance of sentiment classifier\n",
    "print(classification_report(y_test['sentiment'], mlpcClassifierSentiment.predict(X_test)))\n",
    "performanceFile.write(classification_report(y_test['sentiment'], mlpcClassifierSentiment.predict(X_test)))\n",
    "\n",
    "#Confusion matrix\n",
    "print(confusion_matrix(y_test['sentiment'], mlpcClassifierSentiment.predict(X_test)))\n",
    "performanceFile.write(str(confusion_matrix(y_test['sentiment'], mlpcClassifierSentiment.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOP-MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.45      0.51      0.48      2059\n",
      "     amusement       0.50      0.44      0.47      1192\n",
      "         anger       0.34      0.20      0.25      1068\n",
      "     annoyance       0.19      0.11      0.14      1653\n",
      "      approval       0.23      0.13      0.17      2232\n",
      "        caring       0.25      0.16      0.20       694\n",
      "     confusion       0.26      0.13      0.17       939\n",
      "     curiosity       0.36      0.19      0.25      1171\n",
      "        desire       0.35      0.10      0.15       448\n",
      "disappointment       0.21      0.08      0.12       966\n",
      "   disapproval       0.23      0.13      0.17      1523\n",
      "       disgust       0.31      0.14      0.19       562\n",
      " embarrassment       0.42      0.04      0.08       296\n",
      "    excitement       0.26      0.08      0.12       598\n",
      "          fear       0.32      0.09      0.14       355\n",
      "     gratitude       0.71      0.73      0.72      1419\n",
      "         grief       0.00      0.00      0.00        84\n",
      "           joy       0.36      0.19      0.25       886\n",
      "          love       0.58      0.49      0.53      1007\n",
      "   nervousness       0.50      0.03      0.05       148\n",
      "       neutral       0.40      0.72      0.51     11185\n",
      "      optimism       0.40      0.23      0.30       853\n",
      "         pride       0.17      0.01      0.03       148\n",
      "   realization       0.15      0.06      0.08       934\n",
      "        relief       0.25      0.01      0.01       149\n",
      "       remorse       0.48      0.15      0.23       332\n",
      "       sadness       0.35      0.18      0.24       783\n",
      "      surprise       0.36      0.19      0.25       680\n",
      "\n",
      "      accuracy                           0.39     34364\n",
      "     macro avg       0.34      0.20      0.22     34364\n",
      "  weighted avg       0.36      0.39      0.35     34364\n",
      "\n",
      "[[1059   23    6   14   75    8    2   17    2    4    8    2    0    8\n",
      "     3   60    0   34   63    0  615   18    0    8    0    0    3   27]\n",
      " [  48  526    4   28   20    3    6   10    2    4    9    3    0    5\n",
      "     0    7    0   18    9    1  465    5    0    8    0    1    2    8]\n",
      " [  24   11  209  118   27   12    6    7    0   13   28   23    0    2\n",
      "     0    3    0    3    3    0  561    2    1    4    1    0    4    6]\n",
      " [  39   48   79  178   52   11   21   20    1   27   51   27    1    5\n",
      "     4   13    0    5    7    0 1012    5    0   10    0    4   18   15]\n",
      " [ 115   26   12   51  299   30   13   24   12   14   59    5    1    6\n",
      "     3   19    0   14   34    0 1427   26    1   24    0    3    6    8]\n",
      " [  16    4    5   12   21  112    1    3    2    5   14    0    0    0\n",
      "     1   29    0   12    8    0  415   22    0    1    0    3    7    1]\n",
      " [  18   14    4   19   26    1  120   54    0    3   32    2    1    3\n",
      "     0    4    0    0    4    0  610    2    0   12    0    2    2    6]\n",
      " [  26    8    9   24   31    6   40  228    1    2   13    1    0   10\n",
      "     0    9    0    3    4    0  728    4    0    7    0    1    4   12]\n",
      " [  13    4    0    1   15   15    1    2   43    3    4    1    1    2\n",
      "     0   11    0    3    7    0  294   23    0    0    0    0    3    2]\n",
      " [  21    8   12   36   24    7    7    8    3   78   26    9    0    2\n",
      "     5   11    0    3    4    1  634   11    0   13    0    2   37    4]\n",
      " [  23   23   23   69   61   12   26   10    2   11  201   13    2    1\n",
      "     3   10    0    6    3    0  976    9    0   17    0    1   15    6]\n",
      " [  14    7   27   50   13    4    5    3    1   14   21   76    1    0\n",
      "     5    2    0    0    1    0  304    3    0    3    0    0    3    5]\n",
      " [   6    5    4   17    8    1    8    6    0    7    8    5   13    0\n",
      "     1    4    0    1    1    0  189    0    0    2    0    1    5    4]\n",
      " [  87   13    8   15   17    0    2   11    3    6    2    2    1   45\n",
      "     0   11    0   37   13    0  299    6    1    6    0    0    0   13]\n",
      " [   8    3    3   12    5    0    2    3    0    6    4    7    1    1\n",
      "    32    1    0    5    0    0  249    1    0    6    0    0    3    3]\n",
      " [  82    8    2    4   22    7    1    3    0    2    6    0    0    1\n",
      "     0 1032    0   28    2    0  191   19    0    1    0    5    3    0]\n",
      " [   4    0    0    0    1    0    0    0    0    1    1    0    0    0\n",
      "     0    1    0    0    0    0   62    0    0    1    0    1   12    0]\n",
      " [  78  102    2    3   31    4    2    2    5    5    5    2    0    9\n",
      "     1   31    0  170   49    0  368    6    0    6    0    0    0    5]\n",
      " [ 102   11    5    2   19    3    2    1    1    2    2    0    0    0\n",
      "     0    5    0   14  489    0  344    4    0    1    0    0    0    0]\n",
      " [   3    1    0    5    6    3    2    1    1    6    3    2    0    1\n",
      "     2    1    0    0    0    4  102    0    1    0    0    1    2    1]\n",
      " [ 389  174  160  223  408  159  165  184   33  110  297   53    4   56\n",
      "    33  105    2   73  111    2 8045  103    6  124    1    7   83   75]\n",
      " [  44    6    1    9   44   20    5    4    6    3   13    0    0    3\n",
      "     0   23    0   10    7    0  442  199    0    8    1    0    3    2]\n",
      " [  24    1    1    2    6    2    0    0    0    0    2    0    0    2\n",
      "     1    3    0    3    0    0   93    2    2    3    0    0    0    1]\n",
      " [  27   11    7   25   39   13    9    9    3    8   21    1    3    1\n",
      "     2    6    0    9    5    0  650    8    0   52    0    3    6   16]\n",
      " [   9    1    0    0    8    4    2    0    0    0    2    0    0    0\n",
      "     0   10    0   11    2    0   94    3    0    0    1    0    1    1]\n",
      " [   2    2    1    4   11    6    4    2    1    7    7    1    2    0\n",
      "     1   23    0    0    1    0  167    3    0    6    0   49   31    1]\n",
      " [  10    4   13   22   25    6    3    3    2   28   15    3    0    0\n",
      "     3   11    0    6    7    0  452    6    0    3    0   18  140    3]\n",
      " [  38    6   13   16   14    0    8   16    0    4   13    4    0   11\n",
      "     0    2    0    3    4    0  379    2    0   16    0    0    2  129]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.42      0.25      0.31      3724\n",
      "    negative       0.54      0.52      0.53      7770\n",
      "     neutral       0.49      0.49      0.49     11185\n",
      "    positive       0.62      0.70      0.66     11685\n",
      "\n",
      "    accuracy                           0.55     34364\n",
      "   macro avg       0.52      0.49      0.50     34364\n",
      "weighted avg       0.54      0.55      0.54     34364\n",
      "\n",
      "[[ 926  598 1363  837]\n",
      " [ 295 4063 2160 1252]\n",
      " [ 676 1984 5531 2994]\n",
      " [ 306  912 2231 8236]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performanceFile.write(\"Top-MNB classifier for 'emotion'\\n\\n\")\n",
    "\n",
    "#Performance of emotion classifier\n",
    "print(classification_report(y_test['emotion'], topMNBEmotion.predict(X_test)))\n",
    "performanceFile.write(classification_report(y_test['emotion'], topMNBEmotion.predict(X_test)))\n",
    "\n",
    "#Confusion matrix\n",
    "print(confusion_matrix(y_test['emotion'], topMNBEmotion.predict(X_test)))\n",
    "performanceFile.write(str(confusion_matrix(y_test['emotion'], topMNBEmotion.predict(X_test))))\n",
    "\n",
    "performanceFile.write(\"\\n\\nTop-MNB classifier for 'sentiment'\\n\\n\")\n",
    "\n",
    "#Performance of sentiment classifier\n",
    "print(classification_report(y_test['sentiment'], topMNBSentiment.predict(X_test)))\n",
    "performanceFile.write(classification_report(y_test['sentiment'], topMNBSentiment.predict(X_test)))\n",
    "\n",
    "#Confusion matrix\n",
    "print(confusion_matrix(y_test['sentiment'], topMNBSentiment.predict(X_test)))\n",
    "performanceFile.write(str(confusion_matrix(y_test['sentiment'], topMNBSentiment.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.32      0.22      0.26      2059\n",
      "     amusement       0.57      0.34      0.42      1192\n",
      "         anger       0.00      0.00      0.00      1068\n",
      "     annoyance       0.00      0.00      0.00      1653\n",
      "      approval       0.00      0.00      0.00      2232\n",
      "        caring       0.33      0.00      0.01       694\n",
      "     confusion       0.00      0.00      0.00       939\n",
      "     curiosity       0.00      0.00      0.00      1171\n",
      "        desire       0.00      0.00      0.00       448\n",
      "disappointment       0.00      0.00      0.00       966\n",
      "   disapproval       0.00      0.00      0.00      1523\n",
      "       disgust       1.00      0.00      0.00       562\n",
      " embarrassment       0.00      0.00      0.00       296\n",
      "    excitement       0.00      0.00      0.00       598\n",
      "          fear       0.00      0.00      0.00       355\n",
      "     gratitude       0.90      0.71      0.80      1419\n",
      "         grief       0.00      0.00      0.00        84\n",
      "           joy       0.25      0.00      0.00       886\n",
      "          love       0.57      0.62      0.59      1007\n",
      "   nervousness       0.00      0.00      0.00       148\n",
      "       neutral       0.36      0.94      0.52     11185\n",
      "      optimism       0.51      0.22      0.31       853\n",
      "         pride       0.00      0.00      0.00       148\n",
      "   realization       0.00      0.00      0.00       934\n",
      "        relief       0.38      0.02      0.04       149\n",
      "       remorse       0.43      0.54      0.48       332\n",
      "       sadness       0.00      0.00      0.00       783\n",
      "      surprise       0.00      0.00      0.00       680\n",
      "\n",
      "      accuracy                           0.39     34364\n",
      "     macro avg       0.20      0.13      0.12     34364\n",
      "  weighted avg       0.26      0.39      0.26     34364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  461     9     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0    11     0     1    74     0  1493     9     0     0\n",
      "      0     1     0     0]\n",
      " [   29   400     0     0     0     0     2     0     0     0     0     0\n",
      "      0     0     0     4     0     0    10     0   735     5     0     0\n",
      "      0     7     0     0]\n",
      " [   24     4     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     2     0     0     8     0  1019     4     0     0\n",
      "      0     7     0     0]\n",
      " [   29    20     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0    12     0     0    17     0  1563     4     0     0\n",
      "      0     8     0     0]\n",
      " [  114    13     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     7     0     0    38     0  2038    15     0     0\n",
      "      0     7     0     0]\n",
      " [   40     4     0     0     0     2     0     0     0     0     0     0\n",
      "      0     0     0     2     0     0    18     0   601    11     0     0\n",
      "      0    16     0     0]\n",
      " [   13     6     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     9     0   909     1     0     0\n",
      "      0     1     0     0]\n",
      " [   20    13     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     5     0     0    15     0  1112     2     0     0\n",
      "      0     4     0     0]\n",
      " [   16     1     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     2     0     0    12     0   398    19     0     0\n",
      "      0     0     0     0]\n",
      " [   34     6     0     0     0     2     0     0     0     0     1     0\n",
      "      0     0     0     3     0     0     6     0   897    10     0     0\n",
      "      0     7     0     0]\n",
      " [   44    16     0     0     0     0     1     0     0     0     0     0\n",
      "      0     0     0     6     0     0    14     0  1425     4     0     0\n",
      "      0    13     0     0]\n",
      " [    7     3     0     1     0     0     0     0     0     0     0     1\n",
      "      0     0     0     0     0     0     2     0   545     2     0     0\n",
      "      0     1     0     0]\n",
      " [    5     1     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     1     0     0     2     0   277     2     0     0\n",
      "      0     8     0     0]\n",
      " [   26     5     0     0     0     0     0     0     0     1     0     0\n",
      "      0     0     0     3     0     0    16     0   545     1     0     0\n",
      "      0     1     0     0]\n",
      " [    6     6     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0   340     2     0     0\n",
      "      0     1     0     0]\n",
      " [   82     5     1     2     1     0     0     0     0     0     0     0\n",
      "      0     0     0  1013     0     0     8     0   267     4     0     0\n",
      "      5    31     0     0]\n",
      " [    5     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0    73     0     0     0\n",
      "      0     6     0     0]\n",
      " [   59    39     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     4     0     1    46     0   733     4     0     0\n",
      "      0     0     0     0]\n",
      " [   17     9     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     1   620     0   356     4     0     0\n",
      "      0     0     0     0]\n",
      " [    4     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     2     0   140     1     0     0\n",
      "      0     1     0     0]\n",
      " [  246   111     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     2    33     0     0   137     0 10557    57     0     0\n",
      "      0    42     0     0]\n",
      " [   81     9     0     0     0     2     0     0     0     0     0     0\n",
      "      0     0     0     5     0     0    12     0   558   186     0     0\n",
      "      0     0     0     0]\n",
      " [   11     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     2     0   134     1     0     0\n",
      "      0     0     0     0]\n",
      " [   21     8     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0    11     0   879     6     0     0\n",
      "      0     9     0     0]\n",
      " [   10     2     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     4     0     0     1     0   126     3     0     0\n",
      "      3     0     0     0]\n",
      " [    2     3     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     3     0   143     1     0     0\n",
      "      0   180     0     0]\n",
      " [   13     3     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     3     0     1     6     0   689     4     0     0\n",
      "      0    64     0     0]\n",
      " [   10     2     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     2     0     0     4     0   662     0     0     0\n",
      "      0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.45      0.00      0.00      3724\n",
      "    negative       0.67      0.04      0.08      7770\n",
      "     neutral       0.36      0.95      0.52     11185\n",
      "    positive       0.77      0.31      0.44     11685\n",
      "\n",
      "    accuracy                           0.42     34364\n",
      "   macro avg       0.57      0.32      0.26     34364\n",
      "weighted avg       0.58      0.42      0.34     34364\n",
      "\n",
      "[[    5    15  3564   140]\n",
      " [    0   310  7116   344]\n",
      " [    1    48 10572   564]\n",
      " [    5    90  7989  3601]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performanceFile.write(\"Top-DT classifier for 'emotion'\\n\\n\")\n",
    "\n",
    "#Performance of emotion classifier\n",
    "print(classification_report(y_test['emotion'], topDTEmotion.predict(X_test)))\n",
    "performanceFile.write(classification_report(y_test['emotion'], topDTEmotion.predict(X_test)))\n",
    "\n",
    "#Confusion matrix\n",
    "print(confusion_matrix(y_test['emotion'], topDTEmotion.predict(X_test)))\n",
    "performanceFile.write(str(confusion_matrix(y_test['emotion'], topDTEmotion.predict(X_test))))\n",
    "\n",
    "performanceFile.write(\"\\n\\nTop-DT classifier for 'sentiment'\\n\\n\")\n",
    "\n",
    "#Performance of sentiment classifier\n",
    "print(classification_report(y_test['sentiment'], topDTSentiment.predict(X_test)))\n",
    "performanceFile.write(classification_report(y_test['sentiment'], topDTSentiment.predict(X_test)))\n",
    "\n",
    "#Confusion matrix\n",
    "print(confusion_matrix(y_test['sentiment'], topDTSentiment.predict(X_test)))\n",
    "performanceFile.write(str(confusion_matrix(y_test['sentiment'], topDTSentiment.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.47      0.56      0.51      2059\n",
      "     amusement       0.49      0.62      0.54      1192\n",
      "         anger       0.30      0.30      0.30      1068\n",
      "     annoyance       0.19      0.06      0.09      1653\n",
      "      approval       0.20      0.02      0.03      2232\n",
      "        caring       0.28      0.08      0.12       694\n",
      "     confusion       0.27      0.08      0.12       939\n",
      "     curiosity       0.35      0.22      0.27      1171\n",
      "        desire       0.31      0.17      0.22       448\n",
      "disappointment       0.11      0.01      0.02       966\n",
      "   disapproval       0.09      0.01      0.02      1523\n",
      "       disgust       0.24      0.15      0.19       562\n",
      " embarrassment       0.00      0.00      0.00       296\n",
      "    excitement       0.35      0.01      0.02       598\n",
      "          fear       0.29      0.41      0.34       355\n",
      "     gratitude       0.73      0.77      0.75      1419\n",
      "         grief       0.00      0.00      0.00        84\n",
      "           joy       0.31      0.20      0.24       886\n",
      "          love       0.54      0.65      0.59      1007\n",
      "   nervousness       0.00      0.00      0.00       148\n",
      "       neutral       0.43      0.78      0.55     11185\n",
      "      optimism       0.37      0.33      0.34       853\n",
      "         pride       0.00      0.00      0.00       148\n",
      "   realization       0.00      0.00      0.00       934\n",
      "        relief       0.00      0.00      0.00       149\n",
      "       remorse       0.47      0.38      0.42       332\n",
      "       sadness       0.26      0.32      0.29       783\n",
      "      surprise       0.36      0.24      0.28       680\n",
      "\n",
      "      accuracy                           0.42     34364\n",
      "     macro avg       0.26      0.23      0.22     34364\n",
      "  weighted avg       0.35      0.42      0.35     34364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1154   27   16    5   17    4    2    4    4    0    0    5    0    1\n",
      "     6   59    0   48  101    0  548   21    0    0    0    0   13   24]\n",
      " [  40  735    5   10    2    0    0   10    2    0    2    5    0    0\n",
      "     2    3    0   23   12    0  310    4    0    0    0    0    8   19]\n",
      " [  25   17  317   59    2    2    3    5    2    1    4   25    0    0\n",
      "    14    3    0    3    7    0  554    0    0    0    0    5   14    6]\n",
      " [  36   68  168   94    5    6   11   24    4    6    9   32    0    0\n",
      "    28   15    0    4   17    0 1055    8    0    0    0    3   46   14]\n",
      " [ 154   45   24   17   41   17    9   14   10    7   10    8    0    1\n",
      "    19   25    0   18   54    0 1665   47    0    0    0    7   33    7]\n",
      " [  33    8   14    3    7   56    1    5   14    1    5    1    0    0\n",
      "    15   26    0   10   13    0  421   34    0    0    0    8   17    2]\n",
      " [  14   18    8    3    2    0   71   85    1    0    8    5    0    0\n",
      "    14    2    0    3    5    0  675    7    0    0    0    1    9    8]\n",
      " [  20   20   12    5    2    0   26  254    3    2    4    4    0    0\n",
      "     5    6    0   11   11    0  751    8    0    0    0    4   10   13]\n",
      " [  15    6    4    2    5   11    3    6   77    0    0    1    0    0\n",
      "     9   11    0    6   16    0  233   32    0    0    0    0   10    1]\n",
      " [  23   16   25   22    5    4    6    8    7   11   13   21    0    0\n",
      "    22    8    0    4   11    0  628   12    0    0    0    4  106   10]\n",
      " [  18   32   36   35    5    4   12    6    6   15   17   23    0    0\n",
      "    21    6    0    4    7    0 1207   11    0    0    0    7   43    8]\n",
      " [  10   13   74   50    1    1    2    2    1    9   16   86    0    0\n",
      "    20    1    0    0    4    0  238    4    0    0    0    0   26    4]\n",
      " [   5   11    8   23    2    0    2    4    0    3    3   41    0    0\n",
      "     6    1    0    0    3    0  153    1    0    0    0   10   15    5]\n",
      " [  64   25    9    3    1    0    1    7    3    0    0    2    0    6\n",
      "     2   22    0   90   18    0  297   12    0    0    0    1    7   28]\n",
      " [   4    7   15    8    1    1    0    3    0    1    8   10    0    0\n",
      "   147    0    0    0    1    0  129    5    0    0    0    0   12    3]\n",
      " [ 102    8    2    0    7    4    1    8    2    0    0    2    0    0\n",
      "     1 1093    0   33    6    0   90   29    0    0    0   16   10    5]\n",
      " [   5    0    1    2    2    0    0    0    1    1    0    0    0    0\n",
      "     3    0    0    0    2    0   49    0    0    0    0    5   13    0]\n",
      " [ 100  135    6    1    2    2    2    2    4    1    3    1    0    1\n",
      "     1   55    0  179   62    0  288   23    0    0    0    2    9    7]\n",
      " [ 100   12   20    0    3    0    2    2    2    0    0    0    0    0\n",
      "     0   15    0    6  658    0  181    4    0    0    0    1    1    0]\n",
      " [   3    1    3    2    1    1    1    2    2    1    2    3    0    0\n",
      "    20    0    0    0    1    0   77    5    0    2    0    1   16    4]\n",
      " [ 387  240  234  116   61   60   78  231   62   25   68   65    0    4\n",
      "   101   93    0   92  160    0 8683  149    0    0    0   19  179   78]\n",
      " [  43    8    5    2   14   16    9    5   32    0    1    0    0    1\n",
      "     6   22    0   15   13    0  374  278    0    0    0    0    6    3]\n",
      " [  33    4    1    1    3    1    0    2    0    0    0    0    0    0\n",
      "     1    5    0    5    4    0   83    1    0    0    0    0    2    2]\n",
      " [  23   25   15   13    3    4   12   13    2    3    9    2    0    0\n",
      "    18    4    0    6   11    0  703   18    0    0    0    5   27   18]\n",
      " [  12    2    1    2    4    3    0    2    0    0    0    0    0    0\n",
      "     1   20    0    8    2    0   69   12    0    0    0    0    9    2]\n",
      " [   4    7    2    4    1    0    2    1    4    0    6    6    0    0\n",
      "     5    2    0    1    2    0   80   15    0    0    0  127   56    7]\n",
      " [  12    7   12   10    3    6    1    2    2   12    4    9    0    1\n",
      "    19    2    0    2    9    0  353   13    0    0    0   42  251   11]\n",
      " [  30   17   10    9    0    0    7   12    1    0    2    8    0    2\n",
      "     3    2    0   15    3    0  378    8    0    0    0    0   12  161]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.43      0.34      0.38      3724\n",
      "    negative       0.55      0.57      0.56      7770\n",
      "     neutral       0.52      0.51      0.52     11185\n",
      "    positive       0.66      0.70      0.68     11685\n",
      "\n",
      "    accuracy                           0.57     34364\n",
      "   macro avg       0.54      0.53      0.53     34364\n",
      "weighted avg       0.56      0.57      0.57     34364\n",
      "\n",
      "[[1260  604 1164  696]\n",
      " [ 363 4414 1907 1086]\n",
      " [ 931 2019 5698 2537]\n",
      " [ 368  979 2135 8203]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performanceFile.write(\"Top-MLP classifier for 'emotion'\\n\\n\")\n",
    "\n",
    "#Performance of emotion classifier\n",
    "print(classification_report(y_test['emotion'], topMLPEmotion.predict(X_test)))\n",
    "performanceFile.write(classification_report(y_test['emotion'], topMLPEmotion.predict(X_test)))\n",
    "\n",
    "#Confusion matrix\n",
    "print(confusion_matrix(y_test['emotion'], topMLPEmotion.predict(X_test)))\n",
    "performanceFile.write(str(confusion_matrix(y_test['emotion'], topMLPEmotion.predict(X_test))))\n",
    "\n",
    "performanceFile.write(\"\\n\\nTop-MLP classifier for 'sentiment'\\n\\n\")\n",
    "\n",
    "#Performance of sentiment classifier\n",
    "print(classification_report(y_test['sentiment'], topMLPSentiment.predict(X_test)))\n",
    "performanceFile.write(classification_report(y_test['sentiment'], topMLPSentiment.predict(X_test)))\n",
    "\n",
    "#Confusion matrix\n",
    "print(confusion_matrix(y_test['sentiment'], topMLPSentiment.predict(X_test)))\n",
    "performanceFile.write(str(confusion_matrix(y_test['sentiment'], topMLPSentiment.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "performanceFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration: different splits of training & test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.00      0.00      0.00      5320\n",
      "     ambiguous       0.00      0.00      0.00         0\n",
      "     amusement       0.00      0.00      0.00      3019\n",
      "         anger       0.00      0.00      0.00      2585\n",
      "     annoyance       0.00      0.00      0.00      4103\n",
      "      approval       0.00      0.00      0.00      5699\n",
      "        caring       0.00      0.00      0.00      1787\n",
      "     confusion       0.00      0.00      0.00      2473\n",
      "     curiosity       0.00      0.00      0.00      2936\n",
      "        desire       0.00      0.00      0.00      1102\n",
      "disappointment       0.00      0.00      0.00      2341\n",
      "   disapproval       0.00      0.00      0.00      3848\n",
      "       disgust       0.00      0.00      0.00      1436\n",
      " embarrassment       0.00      0.00      0.00       694\n",
      "    excitement       0.00      0.00      0.00      1474\n",
      "          fear       0.00      0.00      0.00       915\n",
      "     gratitude       0.00      0.00      0.00      3497\n",
      "         grief       0.00      0.00      0.00       174\n",
      "           joy       0.00      0.00      0.00      2174\n",
      "          love       0.00      0.00      0.00      2473\n",
      "      negative       0.00      0.00      0.00         0\n",
      "   nervousness       0.00      0.00      0.00       383\n",
      "       neutral       0.32      0.34      0.33     27698\n",
      "      optimism       0.00      0.00      0.00      2248\n",
      "      positive       0.00      0.00      0.00         0\n",
      "         pride       0.00      0.00      0.00       369\n",
      "   realization       0.00      0.00      0.00      2387\n",
      "        relief       0.00      0.00      0.00       374\n",
      "       remorse       0.00      0.00      0.00       748\n",
      "       sadness       0.00      0.00      0.00      1931\n",
      "      surprise       0.00      0.00      0.00      1722\n",
      "\n",
      "      accuracy                           0.11     85910\n",
      "     macro avg       0.01      0.01      0.01     85910\n",
      "  weighted avg       0.10      0.11      0.11     85910\n",
      "\n",
      "[[    0   111     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0   210     0   722     0\n",
      "   4168     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0    78     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0   229     0   477     0\n",
      "   2327     0     0     0     0     0     0]\n",
      " [    0    69     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0  1526     0   696     0\n",
      "    326     0     0     0     0     0     0]\n",
      " [    0   152     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0  1858     0  1394     0\n",
      "    835     0     0     0     0     0     0]\n",
      " [    0   170     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0   821     0  2104     0\n",
      "   2465     0     0     0     0     0     0]\n",
      " [    0    16     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0   286     0   498     0\n",
      "    936     0     0     0     0     0     0]\n",
      " [    0   441     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0   426     0  1141     0\n",
      "    457     0     0     0     0     0     0]\n",
      " [    0   577     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0   360     0  1321     0\n",
      "    691     0     0     0     0     0     0]\n",
      " [    0    17     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0    77     0   303     0\n",
      "    648     0     0     0     0     0     0]\n",
      " [    0    67     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0  1006     0   797     0\n",
      "    495     0     0     0     0     0     0]\n",
      " [    0   129     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0  1428     0  1496     0\n",
      "    785     0     0     0     0     0     0]\n",
      " [    0    24     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0   937     0   345     0\n",
      "    172     0     0     0     0     0     0]\n",
      " [    0    27     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0   369     0   204     0\n",
      "    139     0     0     0     0     0     0]\n",
      " [    0    90     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0   106     0   312     0\n",
      "   1038     0     0     0     0     0     0]\n",
      " [    0    27     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0   528     0   178     0\n",
      "    130     0     0     0     0     0     0]\n",
      " [    0     8     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0    93     0   107     0\n",
      "   3370     0     0     0     0     0     0]\n",
      " [    0     2     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0    76     0    72     0\n",
      "     27     0     0     0     0     0     0]\n",
      " [    0    40     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0    98     0   257     0\n",
      "   1760     0     0     0     0     0     0]\n",
      " [    0    25     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0    69     0   219     0\n",
      "   2171     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0    12     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0   173     0   130     0\n",
      "     98     0     0     0     0     0     0]\n",
      " [    0  1222     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0  4736     0 13736     0\n",
      "   7906     0     0     0     0     0     0]\n",
      " [    0    42     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0   175     0   631     0\n",
      "   1423     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]\n",
      " [    0     4     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0    36     0    90     0\n",
      "    191     0     0     0     0     0     0]\n",
      " [    0   195     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0   478     0  1011     0\n",
      "    643     0     0     0     0     0     0]\n",
      " [    0    10     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0    50     0   104     0\n",
      "    250     0     0     0     0     0     0]\n",
      " [    0    15     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0   496     0   103     0\n",
      "    148     0     0     0     0     0     0]\n",
      " [    0    20     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0  1071     0   425     0\n",
      "    380     0     0     0     0     0     0]\n",
      " [    0   436     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0   261     0   490     0\n",
      "    563     0     0     0     0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.11      0.05      0.07      9518\n",
      "    negative       0.23      0.21      0.22     19158\n",
      "     neutral       0.32      0.34      0.33     27698\n",
      "    positive       0.34      0.40      0.37     29536\n",
      "\n",
      "    accuracy                           0.30     85910\n",
      "   macro avg       0.25      0.25      0.25     85910\n",
      "weighted avg       0.28      0.30      0.29     85910\n",
      "\n",
      "[[ 1649  1525  3963  2354]\n",
      " [  544  9468  5840  3535]\n",
      " [ 1222  4736 13736  7906]\n",
      " [  611  2250  5824 20747]]\n"
     ]
    }
   ],
   "source": [
    "#50% train, 50% test\n",
    "nb_xTrain, nb_xtest, nb_yTrain, nb_yTest = train_test_split(comment_vector, df, test_size=0.5)\n",
    "\n",
    "#Emotion classifier\n",
    "nb_emotion_model2 = nb_classifier.fit(nb_xTrain, nb_yTrain['emotion'])\n",
    "\n",
    "#Sentiment classifier\n",
    "nb_sentiment_model2 =  nb_classifier.fit(nb_xTrain, nb_yTrain['sentiment'])\n",
    "\n",
    "#Showing performance with different training and testing set\n",
    "nb_emotion_model_prediction2 = nb_emotion_model2.predict(nb_xtest)\n",
    "\n",
    "nb_emotion_report2 = classification_report(nb_yTrain['emotion'], nb_emotion_model_prediction2)\n",
    "print(nb_emotion_report2)\n",
    "nb_emotion_confusion_matrix2=confusion_matrix(nb_yTest['emotion'], nb_emotion_model_prediction2)\n",
    "print(nb_emotion_confusion_matrix2)\n",
    "\n",
    "nb_sentiment_model_prediction2 = nb_sentiment_model2.predict(nb_xtest)\n",
    "\n",
    "nb_sentiment_report2 = classification_report(nb_yTrain['sentiment'], nb_sentiment_model_prediction2)\n",
    "print(nb_sentiment_report2)\n",
    "nb_sentiment_confusion_matrix2=confusion_matrix(nb_yTest['sentiment'], nb_sentiment_model_prediction2)\n",
    "print(nb_sentiment_confusion_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.06      0.08      0.07      5321\n",
      "     amusement       0.03      0.04      0.04      3071\n",
      "         anger       0.03      0.04      0.04      2586\n",
      "     annoyance       0.05      0.06      0.05      4178\n",
      "      approval       0.06      0.08      0.07      5625\n",
      "        caring       0.02      0.03      0.02      1789\n",
      "     confusion       0.02      0.03      0.02      2491\n",
      "     curiosity       0.03      0.04      0.04      2909\n",
      "        desire       0.02      0.02      0.02      1088\n",
      "disappointment       0.03      0.03      0.03      2348\n",
      "   disapproval       0.05      0.05      0.05      3864\n",
      "       disgust       0.01      0.01      0.01      1458\n",
      " embarrassment       0.01      0.01      0.01       731\n",
      "    excitement       0.02      0.02      0.02      1490\n",
      "          fear       0.01      0.01      0.01       886\n",
      "     gratitude       0.04      0.04      0.04      3510\n",
      "         grief       0.00      0.00      0.00       177\n",
      "           joy       0.02      0.02      0.02      2185\n",
      "          love       0.03      0.03      0.03      2525\n",
      "   nervousness       0.00      0.00      0.00       395\n",
      "       neutral       0.32      0.30      0.31     27634\n",
      "      optimism       0.02      0.01      0.02      2239\n",
      "         pride       0.01      0.00      0.00       343\n",
      "   realization       0.02      0.01      0.01      2350\n",
      "        relief       0.00      0.00      0.00       387\n",
      "       remorse       0.01      0.01      0.01       738\n",
      "       sadness       0.02      0.01      0.02      1879\n",
      "      surprise       0.03      0.02      0.02      1713\n",
      "\n",
      "      accuracy                           0.12     85910\n",
      "     macro avg       0.04      0.04      0.04     85910\n",
      "  weighted avg       0.13      0.12      0.13     85910\n",
      "\n",
      "[[ 2543   104    42   105   373    56    48    70    37    36    64    17\n",
      "     14   112     8   177     3   131   206     2   834    84    29    32\n",
      "     15     3    16    49]\n",
      " [  155  1554    41   110   110    21    41    25    25    21    60    25\n",
      "      8    37     6    25     0   162    24     1   504    25     2    30\n",
      "      3     3    13    28]\n",
      " [   42    47   742   401   100    31    42    48    12    86   122    99\n",
      "     10    21    17    12     6    13    14     7   656    14     4    21\n",
      "      0     4    16    29]\n",
      " [  147   157   438   735   291    86   101   106    35   165   277   134\n",
      "     47    32    31    26     5    21    33    11  1069    46     4    42\n",
      "      8    21    59    37]\n",
      " [  478   137    97   289  1223   163   128   111    81   110   215    40\n",
      "     19    68    39    49     5   117   110    14  1828   107     7    99\n",
      "     24    19    30    27]\n",
      " [   87    29    35    81   168   418    24    33    35    33    60     7\n",
      "      4     9    14    36     3    49    28     8   447    61     5    10\n",
      "      7    11    23     9]\n",
      " [   51    44    66   151   157    26   602   271    19    39   104    15\n",
      "     16    12    11    16     3    12    22     3   695    18     1    33\n",
      "      1     5    13    41]\n",
      " [   97    45    78   143   105    29   383   848    27    27    75    13\n",
      "     12    50     5    17     1    14    30     6   857    16     1    27\n",
      "      1     5     9    55]\n",
      " [   44    18    19    57    97    26    16    27   263    26    26     6\n",
      "      7    19     7     6     3    16    22     2   259    64     0    19\n",
      "      1     2     3     4]\n",
      " [   60    52   101   245   166    68    53    46    17   294   174    47\n",
      "     25    19    22    11     9    14    14    19   666    26     6    35\n",
      "      7    27   105    30]\n",
      " [   87    90   182   390   301    58   124    70    20   175   791    72\n",
      "     29    20    31    21     6    26    16     9  1107    42     2    55\n",
      "      2    19    50    27]\n",
      " [   42    45   163   214    72    12    29    18    12    68    76   253\n",
      "     23    10    27     5     7     8     8     6   299     9     2    17\n",
      "      1     6    16     8]\n",
      " [   19    28    43    76    39    14    18    13     5    34    32    27\n",
      "     92     8     9     7     3     3    10     1   170     4     0     8\n",
      "      1    13    13    12]\n",
      " [  185    63    29    52    94    18    28    69    28    19    28    10\n",
      "      1   286     5    23     0    63    48     3   357    29     5    17\n",
      "      1     0    12    57]\n",
      " [   23    23    29    57    50    21    18    16     3    24    30    37\n",
      "      8     5   256     2     0     7     6    14   207    13     2    10\n",
      "      1     2    21     7]\n",
      " [  247    27     5    59    70    48     4    12     9    22    24     1\n",
      "      5    52     1  2576     0    68    30     1   189    41     6     5\n",
      "     16    29     8    10]\n",
      " [    6     4    13    10     6     4     5     1     3     7     3     5\n",
      "      1     0     7     4    21     0     2     0    46     2     2     3\n",
      "      0     6    13     0]\n",
      " [  232   261    19    57   110    46     9    24    28    27    26     5\n",
      "      4   117     5    79     3   476   113     3   385    34    20    19\n",
      "     15     1    11    15]\n",
      " [  254    53    17    42   107    31    15    14    29    20    27    10\n",
      "      1    38     3    20     3    96  1323     0   278    22     1    13\n",
      "      3     3     6     3]\n",
      " [    7    10    11    29    26    21    16     9     1    43    18     8\n",
      "      9     7    17     1     0     3     2    32    99     4     0     3\n",
      "      0     2    17     6]\n",
      " [ 1288   723   914  1581  2355   617   953   984   343   674  1303   294\n",
      "    158   331   175   162    44   394   375    84 12501   351    52   393\n",
      "     51    68   251   245]\n",
      " [  167    46    26    86   206   119    48    41   121    39    62    18\n",
      "     11    41     9    45     3    41    27     4   561   490     7    17\n",
      "      4     7    16    18]\n",
      " [   54     2     9    12    37     8     9     7     0    10    14     2\n",
      "      3    12     0    10     1    20     3     0    95     9    19     5\n",
      "      2     0     1     3]\n",
      " [   97    73    67   164   238    50    83    55    23    89   128    16\n",
      "     21    27    21    19     6    21    25     7   820    30     2   188\n",
      "      4    17    29    44]\n",
      " [   34     6     4    10    38    15     6     7     2    10    10     3\n",
      "      1     9     3    31     1    29     6     3   119     8     4     7\n",
      "     28     0     6     1]\n",
      " [   16    11    10    36    29    27    13    10     7    57    25     9\n",
      "     19     1     0    40     6     1     1     2   122     7     0    16\n",
      "      1   232    66     8]\n",
      " [   46    29    65   131   106    61    35    28    17   191    89    24\n",
      "     18    12    25    19    21    14    14    16   444    12     2    38\n",
      "      4   100   378     9]\n",
      " [  134    44    56    89    86    25    93    90     9    48    61    17\n",
      "     23    76    11    12     1    23    13     4   439    11     0    38\n",
      "      2     3     7   344]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.11      0.13      0.12      9463\n",
      "    negative       0.22      0.25      0.24     19240\n",
      "     neutral       0.32      0.31      0.31     27634\n",
      "    positive       0.35      0.30      0.32     29573\n",
      "\n",
      "    accuracy                           0.27     85910\n",
      "   macro avg       0.25      0.25      0.25     85910\n",
      "weighted avg       0.28      0.27      0.28     85910\n",
      "\n",
      "[[ 3989  1642  2629  1286]\n",
      " [ 2025 10544  4537  2199]\n",
      " [ 3688  6208 12805  4963]\n",
      " [ 2127  3474  6861 16933]]\n"
     ]
    }
   ],
   "source": [
    "#50% train, 50% test\n",
    "DT_xTrain, DT_xtest, DT_yTrain, DT_yTest = train_test_split(comment_vector, df, test_size=0.5)\n",
    "\n",
    "#Emotion classifier\n",
    "dtc_emotion_model2 = tree.DecisionTreeClassifier(criterion = \"entropy\")\n",
    "dtc_emotion_model2.fit(DT_xTrain, DT_yTrain['emotion'])\n",
    "\n",
    "\n",
    "#Sentiment classifier\n",
    "dtc_sentiment_model2 = tree.DecisionTreeClassifier(criterion = \"entropy\")\n",
    "dtc_sentiment_model2.fit(DT_xTrain, DT_yTrain['sentiment'])\n",
    "\n",
    "#Showing performance with different training and testing set\n",
    "dtc_emotion_model_prediction2 = dtc_emotion_model2.predict(DT_xtest)\n",
    "\n",
    "dtc_emotion_report2 = classification_report(DT_yTrain['emotion'], dtc_emotion_model_prediction2)\n",
    "print(dtc_emotion_report2)\n",
    "dtc_emotion_confusion_matrix2=confusion_matrix(DT_yTest['emotion'], dtc_emotion_model_prediction2)\n",
    "print(dtc_emotion_confusion_matrix2)\n",
    "\n",
    "dtc_sentiment_model_prediction2 = dtc_sentiment_model2.predict(DT_xtest)\n",
    "\n",
    "dtc_sentiment_report2 = classification_report(DT_yTrain['sentiment'], dtc_sentiment_model_prediction2)\n",
    "print(dtc_sentiment_report2)\n",
    "dtc_sentiment_confusion_matrix2=confusion_matrix(DT_yTest['sentiment'], dtc_sentiment_model_prediction2)\n",
    "print(dtc_sentiment_confusion_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-Layered Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.07      0.07      0.07      5180\n",
      "     amusement       0.04      0.04      0.04      3054\n",
      "         anger       0.03      0.02      0.03      2624\n",
      "     annoyance       0.04      0.04      0.04      4169\n",
      "      approval       0.07      0.05      0.06      5660\n",
      "        caring       0.01      0.01      0.01      1758\n",
      "     confusion       0.03      0.02      0.03      2476\n",
      "     curiosity       0.04      0.03      0.04      2916\n",
      "        desire       0.02      0.02      0.02      1095\n",
      "disappointment       0.03      0.03      0.03      2303\n",
      "   disapproval       0.05      0.04      0.04      3822\n",
      "       disgust       0.02      0.02      0.02      1449\n",
      " embarrassment       0.00      0.00      0.00       700\n",
      "    excitement       0.02      0.02      0.02      1541\n",
      "          fear       0.01      0.01      0.01       827\n",
      "     gratitude       0.04      0.04      0.04      3509\n",
      "         grief       0.00      0.00      0.00       188\n",
      "           joy       0.02      0.02      0.02      2188\n",
      "          love       0.03      0.03      0.03      2429\n",
      "   nervousness       0.01      0.01      0.01       377\n",
      "       neutral       0.32      0.37      0.34     27776\n",
      "      optimism       0.03      0.02      0.02      2276\n",
      "         pride       0.00      0.00      0.00       354\n",
      "   realization       0.02      0.02      0.02      2450\n",
      "        relief       0.00      0.00      0.00       399\n",
      "       remorse       0.01      0.01      0.01       763\n",
      "       sadness       0.02      0.02      0.02      1915\n",
      "      surprise       0.02      0.02      0.02      1712\n",
      "\n",
      "      accuracy                           0.14     85910\n",
      "     macro avg       0.04      0.04      0.04     85910\n",
      "  weighted avg       0.13      0.14      0.13     85910\n",
      "\n",
      "[[ 2436   102    20    85   263    46    40    45    26    40    47    16\n",
      "     12   146     9   177     3   183   255     4  1054   102    41    52\n",
      "     17     4    32    94]\n",
      " [  122  1383    40    94    84    28    46    28    10    45    56    14\n",
      "     18    40     9    28     1   213    44     3   631    27     3    39\n",
      "      5     7    25    33]\n",
      " [   25    40   639   322    69    31    49    38     9    87   120   115\n",
      "     16    17    19    10     4    15    16     4   782    21     6    41\n",
      "      4     9    45    25]\n",
      " [   76   114   270   647   200    76    95    91    29   195   244   123\n",
      "     56    39    36    32     8    41    40    11  1392    45    10    91\n",
      "      3    15   114    80]\n",
      " [  355    76    81   204   947   135   107    86    72   127   221    42\n",
      "     27    90    30    50     4   111    99    15  2228   137    33   148\n",
      "     32    21    72    49]\n",
      " [   59    19    33    61   101   378    24    25    26    48    44    10\n",
      "      9    16    13    36     1    48    31    21   559    88     7    31\n",
      "     11    21    42     3]\n",
      " [   29    41    36    78    76    14   507   250    10    63    85    21\n",
      "     16    22    18    11     1    18    12     4   983    26     5    66\n",
      "      1     8    19    42]\n",
      " [   53    41    28    81    84    30   301   782    26    43    45    12\n",
      "     16    53    11    12     0    20    24     6  1141    23     6    30\n",
      "      4     8    17    72]\n",
      " [   34    10    23    30    50    32    18    21   227    23    21     7\n",
      "      2    34     4     9     1    16    30     2   330    80     5    13\n",
      "      1     5    19     5]\n",
      " [   39    34    66   161    85    39    51    32    22   366   137    60\n",
      "     30    14    26    17    10    15    19    18   773    40     8    86\n",
      "      6    42   159    48]\n",
      " [   74    66   107   262   177    42   112    51    16   188   709    73\n",
      "     27    27    20    14     2    29    30    14  1462    56    11   124\n",
      "      5    29   104    33]\n",
      " [   25    24   118   174    47    10    35    19     7    88    71   246\n",
      "     23     6    39     5     5    10     6     3   405    14     3    23\n",
      "      1     9    30    19]\n",
      " [    6    15    22    56    16    15    18     9     5    42    29    35\n",
      "    125     5     8     6     5     8     5     2   213     6     2    16\n",
      "      3    24    23    14]\n",
      " [  141    58    15    36    55    12    15    45    25    26    19     2\n",
      "      5   287     6    28     0   127    40     4   389    20     9    22\n",
      "      2     2    11    78]\n",
      " [   17    16    26    45    26    15    16    11     6    29    29    29\n",
      "     12     6   298     4     1     3     2    18   264    12     1    19\n",
      "      1     4    25    16]\n",
      " [  225    23     8    37    60    42    11    21     9    20    23     4\n",
      "      2    23     1  2566     4    91    28     0   217    51     5    12\n",
      "     12    42    17    12]\n",
      " [    2     2     7     4     2     1     3     1     2     6     4     3\n",
      "      1     1     4     2    15     0     3     0    57     1     1     2\n",
      "      0     6    32     1]\n",
      " [  179   205    18    29    91    46     9    17    14    32    24     4\n",
      "      2    94     8    74     2   542   136     1   459    40    14    33\n",
      "     20     5    20    23]\n",
      " [  241    30     6    32    66    31    15    15    27    18    18     3\n",
      "      2    51     6    22     1    93  1416     1   349    32     3    20\n",
      "      5     3    13     9]\n",
      " [    6     7     4    19    19    11    11     7     5    30    15     8\n",
      "     10     7    32     2     1     4     1    41   136     7     1     9\n",
      "      0     2    18     6]\n",
      " [  896   546   543  1079  1504   521   681   752   279   719  1007   233\n",
      "    162   341   184   184    35   442   381    59 14756   489   132   663\n",
      "     78   100   425   331]\n",
      " [  105    40    17    48   149    89    34    27   112    44    50     2\n",
      "     13    45     9    43     3    49    39     3   652   561     6    46\n",
      "      6     6    24    21]\n",
      " [   52     6     5    10    35     7     6     2     1     4     2     1\n",
      "      6    11     1    10     2    15     3     0   103    17    26     6\n",
      "      2     0     2     1]\n",
      " [   54    47    38   108   146    28    69    40    21    83   111    26\n",
      "     21    28    15    14     5    31    22     2   921    50     9   268\n",
      "      1    16    48    42]\n",
      " [   26     5     7     7    28    19     4     4     3    12     6     4\n",
      "      1     3     2    31     0    24     3     1   125    14     1     8\n",
      "     37     0     9     5]\n",
      " [    6     6     4    29    13    28    17     8     9    31    16     7\n",
      "     16     4     5    41     3     0     5     3   122     8     2    24\n",
      "      2   234    96     8]\n",
      " [   14    22    29    81    66    52    24    13    15   174    65    27\n",
      "     17    10    25    15    16    15    14    20   513    19     5    30\n",
      "      6   122   489    14]\n",
      " [   91    50    46    53    50    12    52    69     5    54    47    13\n",
      "     18    81    13    13     3    32    10     1   522    12     3    55\n",
      "      3     5    13   434]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.11      0.13      0.12      9463\n",
      "    negative       0.22      0.25      0.24     19240\n",
      "     neutral       0.32      0.31      0.31     27634\n",
      "    positive       0.35      0.30      0.32     29573\n",
      "\n",
      "    accuracy                           0.27     85910\n",
      "   macro avg       0.25      0.25      0.25     85910\n",
      "weighted avg       0.28      0.27      0.28     85910\n",
      "\n",
      "[[ 3295  1471  3067  1622]\n",
      " [ 1375  9853  5264  2916]\n",
      " [ 2575  5059 13292  6596]\n",
      " [ 1414  2784  5778 19549]]\n"
     ]
    }
   ],
   "source": [
    "#50% train, 50% test\n",
    "mlp_xTrain, mlp_xtest, mlp_yTrain, mlp_yTest = train_test_split(comment_vector, df, test_size=0.5)\n",
    "\n",
    "#Emotion classifier\n",
    "mlp_emotion_model2 = MLPClassifier(max_iter=50)\n",
    "mlp_emotion_model2.fit(mlp_xTrain, mlp_yTrain['emotion'])\n",
    "\n",
    "\n",
    "#Sentiment classifier\n",
    "mlp_sentiment_model2 = MLPClassifier(max_iter=50)\n",
    "mlp_sentiment_model2.fit(mlp_xTrain, mlp_yTrain['sentiment'])\n",
    "\n",
    "#Showing performance with different training and testing set\n",
    "mlp_emotion_model_prediction2 = mlp_emotion_model2.predict(mlp_xtest)\n",
    "\n",
    "mlp_emotion_report2 = classification_report(mlp_yTrain['emotion'], mlp_emotion_model_prediction2)\n",
    "print(mlp_emotion_report2)\n",
    "mlp_emotion_confusion_matrix2=confusion_matrix(mlp_yTest['emotion'], mlp_emotion_model_prediction2)\n",
    "print(mlp_emotion_confusion_matrix2)\n",
    "\n",
    "mlp_sentiment_model_prediction2 = mlp_sentiment_model2.predict(mlp_xtest)\n",
    "\n",
    "mlp_sentiment_report2 = classification_report(mlp_yTrain['sentiment'], mlp_sentiment_model_prediction2)\n",
    "print(dtc_sentiment_report2)\n",
    "mlp_sentiment_confusion_matrix2=confusion_matrix(mlp_yTest['sentiment'], mlp_sentiment_model_prediction2)\n",
    "print(mlp_sentiment_confusion_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top - Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.06      0.06      0.06      5292\n",
      "     amusement       0.03      0.02      0.03      3036\n",
      "         anger       0.03      0.01      0.02      2634\n",
      "     annoyance       0.05      0.03      0.03      4108\n",
      "      approval       0.06      0.03      0.04      5601\n",
      "        caring       0.03      0.01      0.01      1765\n",
      "     confusion       0.04      0.01      0.02      2439\n",
      "     curiosity       0.03      0.01      0.02      2883\n",
      "        desire       0.01      0.00      0.00      1079\n",
      "disappointment       0.03      0.01      0.01      2326\n",
      "   disapproval       0.04      0.02      0.02      3827\n",
      "       disgust       0.01      0.00      0.00      1454\n",
      " embarrassment       0.02      0.00      0.00       712\n",
      "    excitement       0.02      0.00      0.01      1546\n",
      "          fear       0.00      0.00      0.00       902\n",
      "     gratitude       0.04      0.04      0.04      3540\n",
      "         grief       0.00      0.00      0.00       188\n",
      "           joy       0.03      0.01      0.02      2164\n",
      "          love       0.03      0.02      0.02      2522\n",
      "   nervousness       0.00      0.00      0.00       392\n",
      "       neutral       0.32      0.67      0.44     27651\n",
      "      optimism       0.03      0.01      0.02      2318\n",
      "         pride       0.00      0.00      0.00       338\n",
      "   realization       0.03      0.01      0.01      2385\n",
      "        relief       0.00      0.00      0.00       393\n",
      "       remorse       0.02      0.00      0.00       750\n",
      "       sadness       0.02      0.01      0.01      1943\n",
      "      surprise       0.02      0.01      0.01      1722\n",
      "\n",
      "      accuracy                           0.23     85910\n",
      "     macro avg       0.04      0.04      0.03     85910\n",
      "  weighted avg       0.13      0.23      0.16     85910\n",
      "\n",
      "[[ 2348    52     8    31   164    17     2    19     4     9    24     3\n",
      "      2    10     0   134     0    55   119     0  2145    44     1    11\n",
      "      0     1     7    29]\n",
      " [  101  1073    19    55    47     1     8    13     2     6    23     3\n",
      "      1    17     0    27     0    49    21     0  1585    10     0    13\n",
      "      0     1     6    13]\n",
      " [   37    21   363   212    42     9     9    25     2    22    50    22\n",
      "      0     8     2     9     0     4    11     0  1689     5     0    13\n",
      "      0     1     7     5]\n",
      " [   87    56   149   359   140    23    20    41     4    54   116    34\n",
      "      1     8     4    44     0     7    12     0  2973    19     0    33\n",
      "      2     3    29    16]\n",
      " [  298    62    23    85   630    36    36    43     8    15   118     6\n",
      "      1     9     1    55     0    23    56     0  4029    57     0    29\n",
      "      0     3    22    13]\n",
      " [   46     3     3    30    56   153     1     6     4    10    25     0\n",
      "      0     1     0    44     0    10    14     1  1281    53     0     2\n",
      "      0     0    12     3]\n",
      " [   32    20    13    44    80     2   203    94     3     5    49     3\n",
      "      0     4     2    17     0     1     7     0  1884     8     0    19\n",
      "      0     0     3     6]\n",
      " [   71    15    15    34    72     8    87   352     3     7    32     2\n",
      "      1     5     0    19     0     1    12     0  2219     8     0    19\n",
      "      0     0     2    18]\n",
      " [   25    12     4    13    42    11     5     4    68     5    10     1\n",
      "      0     2     0     9     0     9    14     0   765    58     0     5\n",
      "      0     0     1     5]\n",
      " [   53    18    16    85    64    15    13    13     1   111    72    15\n",
      "      1     1     1    18     0     6     7     0  1775    25     0    17\n",
      "      0     3    41     9]\n",
      " [   54    39    39   130   154    11    35    20     2    25   372    29\n",
      "      2     2     3    14     0     7    12     0  2839    12     0    26\n",
      "      1     3    18    10]\n",
      " [   31    10    64    96    45     1     2     5     3    18    47   130\n",
      "      3     4     4     6     1     0     6     0   958     6     0     5\n",
      "      0     2    10     3]\n",
      " [   11     8     7    42    17     1     6     5     0     9    14     7\n",
      "     20     0     2     7     0     2     2     0   535     4     0    11\n",
      "      0     4     6     1]\n",
      " [  186    16    11    14    41     4     4    25     1     5    10     4\n",
      "      0    82     2    18     0    98    25     0   866    19     0    12\n",
      "      0     0     2    29]\n",
      " [   22     8     4    25    31     6    11     7     1     9    16    12\n",
      "      0     2    53     1     0     5     2     0   636     3     0    10\n",
      "      0     0     7     5]\n",
      " [  206    19     0    15    27    12     4     3     1     2    11     0\n",
      "      1     2     1  2450     0    47    10     0   671    36     0     2\n",
      "      0     9     4     2]\n",
      " [    3     3     2     3     1     1     2     1     1     0     2     0\n",
      "      0     1     0     3     0     0     1     0   122     1     0     1\n",
      "      0     1    14     0]\n",
      " [  203   155     6    14    60     9     2     4     0     2     6     3\n",
      "      0    26     0    83     0   285   101     0  1162    23     0     8\n",
      "      0     0    10     3]\n",
      " [  238    26     0    12    37     9     3     8     0     4     7     0\n",
      "      0     4     0    25     0    31   895     0  1117     7     0     6\n",
      "      0     0     2     4]\n",
      " [    1     2     3    10    22     6     2     3     0     6     8     1\n",
      "      0     4     4     5     1     1     0     1   312     1     0     5\n",
      "      0     0     5     1]\n",
      " [  844   353   334   556  1057   195   256   345    38   164   582    74\n",
      "      9    93    36   235     2   175   214     0 21399   202     3   199\n",
      "      1    20   128   133]\n",
      " [   86    13     3    18    88    36    11     8     8     6    28     0\n",
      "      0     3     0    35     0    20    10     0  1455   356     0     5\n",
      "      1     0     4     7]\n",
      " [   57     0     4     7    16     6     0     2     1     3     4     0\n",
      "      0     2     1    11     0     6     3     0   222     2     0     3\n",
      "      0     0     2     0]\n",
      " [   49    27    12    40   102     9    15    16     1    18    43     4\n",
      "      3     5     1    14     0    10     7     0  1801    15     0   105\n",
      "      0     4     8    20]\n",
      " [   22     0     2     4    20     3     1     3     0     4     7     0\n",
      "      0     2     0    33     0     6     3     0   275     3     0     3\n",
      "      2     0     2     0]\n",
      " [    4     4     4    15    28     9     1     5     1     8    12     2\n",
      "      1     0     0    55     0     1     1     1   479     3     0     2\n",
      "      0    59    65     0]\n",
      " [   16    14    11    37    37    12     3     3     2    42    40     5\n",
      "      2     2     3    23     0     7     4     0  1363    14     0     7\n",
      "      0    19   211     7]\n",
      " [   99    24    25    26    39     4    15    33     0    14    17     4\n",
      "      0    14     3    22     0    12     4     0  1178     6     0    17\n",
      "      0     0     6   188]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.11      0.05      0.07      9429\n",
      "    negative       0.22      0.21      0.21     19236\n",
      "     neutral       0.32      0.34      0.33     27651\n",
      "    positive       0.34      0.40      0.37     29594\n",
      "\n",
      "    accuracy                           0.30     85910\n",
      "   macro avg       0.25      0.25      0.24     85910\n",
      "weighted avg       0.28      0.30      0.29     85910\n",
      "\n",
      "[[ 1806  1460  3871  2443]\n",
      " [  575  9424  5864  3446]\n",
      " [ 1312  4743 13601  7991]\n",
      " [  615  2287  5801 20671]]\n",
      "best estimator for emotion classification:  MultinomialNB(alpha=0.5)\n",
      "best estimator for sentiment classification:  MultinomialNB(alpha=1)\n"
     ]
    }
   ],
   "source": [
    "#50% train, 50% test\n",
    "tmnb_xTrain, tmnb_xtest, tmnb_yTrain, tmnb_yTest = train_test_split(comment_vector, df, test_size=0.5)\n",
    "\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# parameters\n",
    "param = {'alpha': [0, 0.5, 1, 2]} \n",
    "\n",
    "#Emotion classifier\n",
    "tmnb_emotion_model2 = GridSearchCV(mnb, param)\n",
    "tmnb_emotion_model2.fit(tmnb_xTrain, tmnb_yTrain['emotion'])\n",
    "\n",
    "\n",
    "#Sentiment classifier\n",
    "tmnb_sentiment_model2 = GridSearchCV(mnb, param)\n",
    "tmnb_sentiment_model2.fit(tmnb_xTrain, tmnb_yTrain['sentiment'])\n",
    "\n",
    "\n",
    "\n",
    "#Showing performance with different training and testing set\n",
    "tmnb_emotion_model_prediction2 = tmnb_emotion_model2.predict(tmnb_xtest)\n",
    "\n",
    "tmnb_emotion_report2 = classification_report(tmnb_yTrain['emotion'], tmnb_emotion_model_prediction2)\n",
    "print(tmnb_emotion_report2)\n",
    "tmnb_emotion_confusion_matrix2=confusion_matrix(tmnb_yTest['emotion'], tmnb_emotion_model_prediction2)\n",
    "print(tmnb_emotion_confusion_matrix2)\n",
    "\n",
    "tmnb_sentiment_model_prediction2 = tmnb_sentiment_model2.predict(tmnb_xtest)\n",
    "\n",
    "tmnb_sentiment_report2 = classification_report(tmnb_yTrain['sentiment'], tmnb_sentiment_model_prediction2)\n",
    "print(tmnb_sentiment_report2)\n",
    "tmnb_sentiment_confusion_matrix2=confusion_matrix(tmnb_yTest['sentiment'], tmnb_sentiment_model_prediction2)\n",
    "print(tmnb_sentiment_confusion_matrix2)\n",
    "\n",
    "\n",
    "#best estimator\n",
    "print(\"best estimator for emotion classification: \",tmnb_emotion_model2.best_estimator_)\n",
    "print(\"best estimator for sentiment classification: \", tmnb_sentiment_model2.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.05      0.01      0.02      5265\n",
      "     amusement       0.04      0.02      0.03      3027\n",
      "         anger       0.00      0.00      0.00      2605\n",
      "     annoyance       0.00      0.00      0.00      4116\n",
      "      approval       0.00      0.00      0.00      5648\n",
      "        caring       0.03      0.00      0.00      1699\n",
      "     confusion       0.00      0.00      0.00      2523\n",
      "     curiosity       0.00      0.00      0.00      2946\n",
      "        desire       0.00      0.00      0.00      1096\n",
      "disappointment       0.00      0.00      0.00      2324\n",
      "   disapproval       0.09      0.00      0.00      3832\n",
      "       disgust       0.00      0.00      0.00      1454\n",
      " embarrassment       0.00      0.00      0.00       716\n",
      "    excitement       0.00      0.00      0.00      1520\n",
      "          fear       0.00      0.00      0.00       925\n",
      "     gratitude       0.04      0.03      0.03      3472\n",
      "         grief       0.00      0.00      0.00       180\n",
      "           joy       0.00      0.00      0.00      2127\n",
      "          love       0.03      0.03      0.03      2518\n",
      "   nervousness       0.00      0.00      0.00       389\n",
      "       neutral       0.32      0.87      0.47     27770\n",
      "      optimism       0.02      0.01      0.01      2230\n",
      "         pride       0.00      0.00      0.00       355\n",
      "   realization       0.00      0.00      0.00      2349\n",
      "        relief       0.00      0.00      0.00       368\n",
      "       remorse       0.00      0.01      0.01       768\n",
      "       sadness       0.00      0.00      0.00      1946\n",
      "      surprise       0.00      0.00      0.00      1742\n",
      "\n",
      "      accuracy                           0.29     85910\n",
      "     macro avg       0.02      0.04      0.02     85910\n",
      "  weighted avg       0.12      0.29      0.16     85910\n",
      "\n",
      "[[  802    33     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0    29     0     3   199     0  4158    38     0     0\n",
      "      0     4     0     0]\n",
      " [   15  1034     0     0     1     0     0     0     0     0     1     0\n",
      "      0     0     0    15     0     1    52     0  1961    12     0     0\n",
      "      0    11     0     0]\n",
      " [    5    12     0     0     0     1     0     0     0     0     2     0\n",
      "      0     0     0    13     0     0    14     0  2535     7     0     0\n",
      "      0     8     0     0]\n",
      " [   21    61     0     1     1     1     0     0     1     0     1     0\n",
      "      1     0     0    34     0     0    41     0  4027    13     0     0\n",
      "      0    23     0     0]\n",
      " [   62    46     0     0     0     1     0     0     0     0     3     0\n",
      "      0     0     0    14     0     1    85     0  5355    30     0     0\n",
      "      1    12     1     0]\n",
      " [   11     7     0     0     0     2     0     0     0     0     1     0\n",
      "      0     0     0     8     0     1    37     0  1684    30     0     0\n",
      "      0    43     0     0]\n",
      " [   10    29     0     0     0     0     0     1     0     0     2     0\n",
      "      0     0     0    10     0     0    13     0  2338     4     0     0\n",
      "      0     8     0     0]\n",
      " [   17    32     0     0     0     0     0     0     0     0     2     0\n",
      "      0     0     0    11     0     0    24     0  2837     4     0     0\n",
      "      0    12     0     0]\n",
      " [   11     7     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     3     0     0    44     0   929    55     0     0\n",
      "      0     2     0     0]\n",
      " [   10    23     0     0     0     3     0     0     0     0     0     0\n",
      "      1     0     0     8     0     0     9     0  2281    13     0     0\n",
      "      0    34     0     0]\n",
      " [   21    32     0     0     0     2     0     0     0     0     2     0\n",
      "      0     0     0    18     0     1    27     0  3701    20     0     0\n",
      "      0    29     1     0]\n",
      " [    5    18     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     2     0     0     6     0  1416     6     0     0\n",
      "      0     7     0     0]\n",
      " [    2     9     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     2     0     0     4     0   678     4     0     0\n",
      "      0    18     0     0]\n",
      " [   44    15     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     7     0     1    33     0  1392     4     0     0\n",
      "      0     4     0     0]\n",
      " [    5    11     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     1     0     0     6     0   822     5     0     0\n",
      "      0     3     0     0]\n",
      " [   60    10     0     1     0     7     0     1     6     0     1     0\n",
      "      0     0     0  2600     0     3    26     0   807    11     0     0\n",
      "      0    70     0     0]\n",
      " [    2     1     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     1     0     0     1     0   153     1     0     0\n",
      "      0    12     0     0]\n",
      " [   36    73     0     0     0     0     0     0     0     0     2     0\n",
      "      0     0     0    15     0     5   115     0  1939    14     0     0\n",
      "      0     3     0     0]\n",
      " [    4    11     0     0     0     0     0     0     0     0     6     0\n",
      "      0     0     0    14     0     0  1497     0   898     7     0     0\n",
      "      0     2     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     1     0     0     4     0   395     4     0     0\n",
      "      0     3     0     0]\n",
      " [  154   285     0     0     0     5     0     2     4     0     5     0\n",
      "      0     0     0   102     0     0   298     0 26430   140     0     0\n",
      "      0   103     0     0]\n",
      " [   35    23     0     0     0     4     0     0     0     0     3     0\n",
      "      0     0     0    12     0     2    34     0  1680   490     0     0\n",
      "      0     6     0     0]\n",
      " [    6     3     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     1     0     0     2     0   319     3     0     0\n",
      "      0     1     0     0]\n",
      " [   18    19     0     0     0     2     0     0     0     0     1     0\n",
      "      0     0     0    10     0     0    29     0  2266     7     0     0\n",
      "      0    13     0     0]\n",
      " [    2     6     0     0     1     0     0     0     3     0     0     0\n",
      "      0     0     0    14     0     0     2     0   386     2     0     0\n",
      "      4     0     0     0]\n",
      " [    3     3     0     0     0     5     0     0     0     0     0     0\n",
      "      0     0     0     2     0     0     2     0   329     1     0     0\n",
      "      0   397     0     0]\n",
      " [    5    12     0     0     0     1     0     0     0     0     0     0\n",
      "      0     0     0     5     0     0    14     0  1654    15     0     0\n",
      "      0   175     0     0]\n",
      " [   16    14     0     0     0     0     0     0     0     0     1     0\n",
      "      0     0     0     9     0     0     7     0  1678     2     0     0\n",
      "      0     3     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.23      0.00      0.00      9560\n",
      "    negative       0.24      0.01      0.03     19255\n",
      "     neutral       0.32      0.85      0.47     27770\n",
      "    positive       0.34      0.13      0.19     29325\n",
      "\n",
      "    accuracy                           0.32     85910\n",
      "   macro avg       0.28      0.25      0.17     85910\n",
      "weighted avg       0.30      0.32      0.22     85910\n",
      "\n",
      "[[    8    44  9023   374]\n",
      " [    6   740 17769   775]\n",
      " [    8   118 26077  1325]\n",
      " [    9   196 20398  9040]]\n",
      "best estimator for emotion classification:  DecisionTreeClassifier(max_depth=8, min_samples_split=3)\n",
      "best estimator for sentiment classification:  DecisionTreeClassifier(max_depth=8, min_samples_split=3)\n"
     ]
    }
   ],
   "source": [
    "#50% train, 50% test\n",
    "tdt_xTrain, tdt_xtest, tdt_yTrain, tdt_yTest = train_test_split(comment_vector, df, test_size=0.5)\n",
    "\n",
    "dt=tree.DecisionTreeClassifier()\n",
    "\n",
    "# parameters\n",
    "param = {'criterion': ['entropy', 'gini'], 'max_depth': [3, 8], 'min_samples_split': [3,5]}\n",
    "\n",
    "#Emotion classifier\n",
    "tdt_emotion_model2 = GridSearchCV(dt, param)\n",
    "tdt_emotion_model2.fit(tdt_xTrain, tdt_yTrain['emotion'])\n",
    "\n",
    "\n",
    "#Sentiment classifier\n",
    "tdt_sentiment_model2 = GridSearchCV(dt, param)\n",
    "tdt_sentiment_model2.fit(tdt_xTrain, tdt_yTrain['sentiment'])\n",
    "\n",
    "#could over fit if the training data is small\n",
    "\n",
    "#Showing performance with different training and testing set\n",
    "tdt_emotion_model_prediction2 = tdt_emotion_model2.predict(tdt_xtest)\n",
    "\n",
    "tdt_emotion_report2 = classification_report(tdt_yTrain['emotion'], tdt_emotion_model_prediction2)\n",
    "print(tdt_emotion_report2)\n",
    "tdt_emotion_confusion_matrix2=confusion_matrix(tdt_yTest['emotion'], tdt_emotion_model_prediction2)\n",
    "print(tdt_emotion_confusion_matrix2)\n",
    "\n",
    "tdt_sentiment_model_prediction2 = tdt_sentiment_model2.predict(tdt_xtest)\n",
    "\n",
    "tdt_sentiment_report2 = classification_report(tdt_yTrain['sentiment'], tdt_sentiment_model_prediction2)\n",
    "print(tdt_sentiment_report2)\n",
    "tdt_sentiment_confusion_matrix2=confusion_matrix(tdt_yTest['sentiment'], tdt_sentiment_model_prediction2)\n",
    "print(tdt_sentiment_confusion_matrix2)\n",
    "\n",
    "#best estimator\n",
    "print(\"best estimator for emotion classification: \",tdt_emotion_model2.best_estimator_)\n",
    "print(\"best estimator for sentiment classification: \", tdt_sentiment_model2.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "20 fits failed out of a total of 80.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 503, in _validate_hyperparameters\n",
      "    raise ValueError(\n",
      "ValueError: The activation 'sigmoid' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.39392387 0.32172041\n",
      " 0.39324875 0.32170876 0.40226982 0.32170876 0.3867885  0.32170876\n",
      " 0.39286463 0.32192993 0.39923175 0.32192993]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "20 fits failed out of a total of 80.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n",
      "    self._validate_hyperparameters()\n",
      "  File \"C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 503, in _validate_hyperparameters\n",
      "    raise ValueError(\n",
      "ValueError: The activation 'sigmoid' is not supported. Supported activations are ['identity', 'logistic', 'relu', 'softmax', 'tanh'].\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.53773717 0.42692352\n",
      " 0.54035619 0.42295425 0.53884298 0.39881271 0.53933186 0.37044582\n",
      " 0.53663136 0.43049703 0.53815621 0.43270865]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\calch\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    admiration       0.06      0.06      0.06      5318\n",
      "     amusement       0.04      0.04      0.04      3102\n",
      "         anger       0.02      0.02      0.02      2564\n",
      "     annoyance       0.04      0.03      0.03      4193\n",
      "      approval       0.06      0.05      0.05      5623\n",
      "        caring       0.02      0.01      0.01      1724\n",
      "     confusion       0.03      0.01      0.02      2420\n",
      "     curiosity       0.04      0.03      0.03      2932\n",
      "        desire       0.01      0.01      0.01      1098\n",
      "disappointment       0.04      0.02      0.03      2330\n",
      "   disapproval       0.04      0.03      0.04      3816\n",
      "       disgust       0.01      0.01      0.01      1448\n",
      " embarrassment       0.01      0.00      0.00       668\n",
      "    excitement       0.02      0.01      0.01      1566\n",
      "          fear       0.01      0.01      0.01       890\n",
      "     gratitude       0.04      0.04      0.04      3561\n",
      "         grief       0.00      0.00      0.00       175\n",
      "           joy       0.03      0.02      0.03      2181\n",
      "          love       0.03      0.03      0.03      2468\n",
      "   nervousness       0.00      0.00      0.00       430\n",
      "       neutral       0.32      0.48      0.38     27638\n",
      "      optimism       0.03      0.02      0.02      2220\n",
      "         pride       0.00      0.00      0.00       344\n",
      "   realization       0.03      0.02      0.02      2356\n",
      "        relief       0.00      0.00      0.00       382\n",
      "       remorse       0.01      0.01      0.01       757\n",
      "       sadness       0.03      0.02      0.03      1945\n",
      "      surprise       0.02      0.02      0.02      1761\n",
      "\n",
      "      accuracy                           0.17     85910\n",
      "     macro avg       0.04      0.04      0.03     85910\n",
      "  weighted avg       0.13      0.17      0.14     85910\n",
      "\n",
      "[[ 2530    97    14    40   255    34    14    52    16    25    46    17\n",
      "      1    60     9   170     0   147   201     2  1262    86     1    18\n",
      "      0     2     8   106]\n",
      " [   96  1714    30    65    45     5    20    20    13     7    37     6\n",
      "      7    10     6    40     0   105    34     0   669    19     0    24\n",
      "      0     9    13    34]\n",
      " [   29    36   633   300    68    18    18    38     7    27   103    93\n",
      "     14     8    20    22     0     7    12     0  1102     7     0    18\n",
      "      0     6    31    21]\n",
      " [   81   119   239   466   137    40    53    79    19    82   241   145\n",
      "     27    18    29    41     0    15    29     0  2063    33     0    53\n",
      "      1    20    67    52]\n",
      " [  335   118    51   117   883    93    55    73    39    50   190    44\n",
      "     14    26    27    50     0    82   100     2  2967   114     0    89\n",
      "      2    19    46    50]\n",
      " [   41    19    22    39    85   279    10    22    19    24    39    12\n",
      "      6     2     5    31     0    41    26     0   856   105     0    17\n",
      "      2    26    63     8]\n",
      " [   31    57    25    61    79    15   372   236     3    23    70    13\n",
      "      5     8    14    17     0     5    14     1  1352    22     0    36\n",
      "      0    10    16    33]\n",
      " [   44    40    24    57    94    15   133   660     6    16    38    14\n",
      "      7    29    12    13     0    17    16     0  1589    27     0    27\n",
      "      0     5     9    61]\n",
      " [   19    12     8    14    48    14     7    14   250    16    18     3\n",
      "      2    11     2     8     0    22    26     0   454    73     0    14\n",
      "      1     1     9     3]\n",
      " [   36    28    52   124    88    25    26    25    22   240    83    62\n",
      "     17     7    20    13     0    13    13     0  1188    34     0    50\n",
      "      2    32   148    28]\n",
      " [   45    75    86   154   190    29    71    50    10    69   630    75\n",
      "     19     6    15    31     0    16    28     0  2037    47     0    61\n",
      "      1    15    68    42]\n",
      " [   19    21   118   123    43     5     8    13     3    29    65   318\n",
      "      9     0    43     3     0     8    12     0   556    12     1    14\n",
      "      1     6    25    11]\n",
      " [    7    11    18    61    26     4     8     5     3    14    21    38\n",
      "    104     3    12     3     0     6    12     1   329     3     0    19\n",
      "      0    26    18    13]\n",
      " [  148    53    20    18    44     9     3    52    12    11     7     2\n",
      "      0   188     5    26     0    94    42     1   582    24     0    10\n",
      "      0     2    10    91]\n",
      " [    2    19    17    23    29    10     4     9    12    19    19    28\n",
      "      9     4   336     0     0     3     3     2   291     7     1    12\n",
      "      0     2    18     9]\n",
      " [  214    15     8    13    34    20     9    14     6     2     9     3\n",
      "      1    12     1  2676     0   109    21     0   209    59     0     4\n",
      "      4    51    19     1]\n",
      " [    3     2     3     6     2     3     3     1     0     4     1     1\n",
      "      5     0     4     2     0     3     1     0    97     2     0     0\n",
      "      0     6    26     1]\n",
      " [  209   265    19    13    79    24     5    12    15     9     7     5\n",
      "      0    64     5    62     0   589   119     0   572    25     0    18\n",
      "      2     5    10    15]\n",
      " [  162    24     7    12    52    14     5    13    21     4    19     2\n",
      "      3    10     1    18     0    78  1457     0   541    13     0    16\n",
      "      0     1     8     8]\n",
      " [    3     4     5    19    17    11    10     5     5    13     8     5\n",
      "      6     9    21     1     0     3     1     9   176     7     0     8\n",
      "      1     2    15     2]\n",
      " [  731   656   449   696  1427   294   392   696   197   306   841   238\n",
      "     76   168   162   191     0   270   351     4 18043   410     2   366\n",
      "      6    85   336   267]\n",
      " [  109    23     9    27   147    56    15    23    55    28    38     8\n",
      "      6    14     6    29     0    46    35     0   873   699     0    21\n",
      "      1     4    13    14]\n",
      " [   58     8     2     6    27     4     1     3     3     4     5     2\n",
      "      3     4     0    10     0    22     1     0   158     7     0     7\n",
      "      0     0     8     3]\n",
      " [   48    62    18    57   136    18    39    41    17    38    96    22\n",
      "      4    14    19    12     0    21    24     0  1300    34     0   199\n",
      "      4    18    37    80]\n",
      " [   25     7     5     7    36    14     0     3     0     5    10     0\n",
      "      0     2     1    42     0    31     3     0   183    12     0     6\n",
      "      2     2     5     5]\n",
      " [    3     7     3    18    12     7     7     5     7    16    17     1\n",
      "      8     0     2    18     0     2     2     0   180    16     0     8\n",
      "      1   301   109     3]\n",
      " [   11    29    24    40    59    31     8     5    15    86    53    29\n",
      "      8     5    15    19     0     6     8     0   724    18     0    18\n",
      "      1   127   528    15]\n",
      " [   77    37    32    42    31     7    22    59     2    14    28    15\n",
      "      5    43    16     8     0    18    10     0   675    13     0    26\n",
      "      0     1    17   513]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   ambiguous       0.11      0.09      0.10      9469\n",
      "    negative       0.22      0.24      0.23     19216\n",
      "     neutral       0.32      0.30      0.31     27638\n",
      "    positive       0.34      0.37      0.36     29587\n",
      "\n",
      "    accuracy                           0.29     85910\n",
      "   macro avg       0.25      0.25      0.25     85910\n",
      "weighted avg       0.28      0.29      0.28     85910\n",
      "\n",
      "[[ 2847  1641  3176  1876]\n",
      " [ 1049 10888  4653  2739]\n",
      " [ 2219  5646 13014  6781]\n",
      " [ 1120  2903  5116 20242]]\n",
      "best estimator for emotion classification:  MLPClassifier(hidden_layer_sizes=(30, 50), max_iter=5)\n",
      "best estimator for sentiment classification:  MLPClassifier(activation='tanh', hidden_layer_sizes=(10, 10, 10), max_iter=5)\n"
     ]
    }
   ],
   "source": [
    "#50% train, 50% test\n",
    "tmlp_xTrain, tmlp_xtest, tmlp_yTrain, tmlp_yTest = train_test_split(comment_vector, df, test_size=0.5)\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "param = {'activation': ['sigmoid', 'tanh', 'relu', 'identity'], 'hidden_layer_sizes': [(30, 50), (10, 10, 10)], 'solver': ['adam', 'sgd'], 'max_iter': [5]}\n",
    "\n",
    "#Emotion classifier\n",
    "tmlp_emotion_model2 = GridSearchCV(mlp, param)\n",
    "tmlp_emotion_model2.fit(tmlp_xTrain, tmlp_yTrain['emotion'])\n",
    "\n",
    "\n",
    "#Sentiment classifier\n",
    "tmlp_sentiment_model2 = GridSearchCV(mlp, param)\n",
    "tmlp_sentiment_model2.fit(tmlp_xTrain, tmlp_yTrain['sentiment'])\n",
    "\n",
    "\n",
    "#Showing performance with different training and testing set\n",
    "tmlp_emotion_model_prediction2 = tmlp_emotion_model2.predict(tmlp_xtest)\n",
    "\n",
    "tmlp_emotion_report2 = classification_report(tmlp_yTrain['emotion'], tmlp_emotion_model_prediction2)\n",
    "print(tmlp_emotion_report2)\n",
    "tmlp_emotion_confusion_matrix2=confusion_matrix(tmlp_yTest['emotion'], tmlp_emotion_model_prediction2)\n",
    "print(tmlp_emotion_confusion_matrix2)\n",
    "\n",
    "tmlp_sentiment_model_prediction2 = tmlp_sentiment_model2.predict(tmlp_xtest)\n",
    "\n",
    "tmlp_sentiment_report2 = classification_report(tmlp_yTrain['sentiment'], tmlp_sentiment_model_prediction2)\n",
    "print(tmlp_sentiment_report2)\n",
    "tmlp_sentiment_confusion_matrix2=confusion_matrix(tmlp_yTest['sentiment'], tmlp_sentiment_model_prediction2)\n",
    "print(tmlp_sentiment_confusion_matrix2)\n",
    "\n",
    "#best estimator\n",
    "print(\"best estimator for emotion classification: \",tmlp_emotion_model2.best_estimator_)\n",
    "print(\"best estimator for sentiment classification: \", tmlp_sentiment_model2.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Embeddings as Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Load word2vec model\n",
    "\n",
    "We will be downloading the `word2vec-google-news-300` model using Gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Tokenize data\n",
    "\n",
    "Install required NLTK data and tokenize sentences into individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment when running for the first time\n",
    "# nltk.download('popular')\n",
    "\n",
    "tokenized_comments = df['comment'].apply(nltk.word_tokenize)\n",
    "tokens = np.concatenate(tokenized_comments.to_numpy())\n",
    "unique_tokens_count = len(np.unique(tokens))\n",
    "print('Number of unique tokens in dataset: ' + str(unique_tokens_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Calculate sentence vector (by taking average of word vectors)\n",
    "\n",
    "Here I have created two functions. The first function calculates the average vector of a sentence by averaging its individual word vectors. The second function calls the first function for a collection of sentences and returns an array containing each average vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average of single sentence\n",
    "def get_avg_vector(sentence, model, vector_size):\n",
    "    words = [word for word in sentence if word in model]\n",
    "    if len(words) >= 1:\n",
    "        return np.mean(model[words], axis=0)\n",
    "    else:\n",
    "        return np.zeros(vector_size) # Set length of vector to 0 for all dimensions\n",
    "\n",
    "# Get averages of collection of sentences\n",
    "def get_avg_vectors(tokenized, model, vector_size):\n",
    "    avg_vectors = []\n",
    "    for comment in tokenized:\n",
    "        avg_vectors.append(get_avg_vector(comment, model, vector_size))\n",
    "    return avg_vectors\n",
    "\n",
    "# Get average vector\n",
    "avg_word2vec = get_avg_vectors(tokenized_comments, word2vec_model, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 - Compute and display overall hit rate\n",
    "\n",
    "The overall hit rate is calculated by counting the number of zero vectors and dividing it by the total amount of vectors in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_hit_rate(tokens, model):\n",
    "    count = 0\n",
    "    for token in tokens:\n",
    "        if token in model:\n",
    "            count += 1\n",
    "    return count / len(tokens)\n",
    "\n",
    "hit_rate = count_hit_rate(tokens, word2vec_model)\n",
    "print(\"Hit rate for dataset: \" + str(hit_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 - Train base MLP models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(avg_word2vec, df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_emotion = MLPClassifier(max_iter=10)\n",
    "mlp_emotion.fit(X_train_w2v, y_train_w2v['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_sentiment = MLPClassifier(max_iter=10)\n",
    "mlp_sentiment.fit(X_train_w2v, y_train_w2v['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 - Train \"Top\" MLP models\n",
    "\n",
    "For this question, we are allowed to choose whichever hyper-parameters we would like. I chose to try adding another hidden layer to see how it would affect our results compared to the base MLP models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_mlp_emotion = MLPClassifier(early_stopping=True, hidden_layer_sizes=(100, 100))\n",
    "top_mlp_emotion.fit(X_train_w2v, y_train_w2v['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_mlp_sentiment = MLPClassifier(early_stopping=True, hidden_layer_sizes=(100, 100))\n",
    "top_mlp_sentiment.fit(X_train_w2v, y_train_w2v['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 - Classification report\n",
    "\n",
    "Here we will simply be calling the `classification_report()` function and piping the output to a file called `performance.txt`.\n",
    "\n",
    "Note: if UndefinedMetricWarning shows, it simply means that our model never predicts certain labels (eg. may never predict a post as being labelled 'grief'. This can usually be fixed by increasing the number of iterations.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_emotion = mlp_emotion.predict(X_test_w2v)\n",
    "y_pred_sentiment = mlp_sentiment.predict(X_test_w2v)\n",
    "y_pred_top_emotion = top_mlp_emotion.predict(X_test_w2v)\n",
    "y_pred_top_sentiment = top_mlp_sentiment.predict(X_test_w2v)\n",
    "\n",
    "with open('performance.txt', 'w') as f:\n",
    "    f.write('Base-MLP emotion classifier\\n\\n')\n",
    "    f.write(classification_report(y_pred_emotion, y_test_w2v['emotion']))\n",
    "    f.write('\\n\\n')\n",
    "\n",
    "    f.write('Base-MLP sentiment classifier\\n\\n')\n",
    "    f.write(classification_report(y_pred_sentiment, y_test_w2v['sentiment']))\n",
    "    f.write('\\n\\n')\n",
    "\n",
    "    f.write('Top-MLP emotion classifier\\n\\n')\n",
    "    f.write(classification_report(y_pred_top_emotion, y_test_w2v['emotion']))\n",
    "    f.write('\\n\\n')\n",
    "\n",
    "    f.write('Top-MLP sentiment classifier\\n\\n')\n",
    "    f.write(classification_report(y_pred_top_sentiment, y_test_w2v['sentiment']))\n",
    "    f.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 - Two other pretrained embedding models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load two pretrained models using gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "glove_twitter_model = api.load('glove-twitter-200')\n",
    "glove_wiki_model = api.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get average vectors with new model and split data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter\n",
    "avg_tw = get_avg_vectors(tokenized_comments, glove_twitter_model, 200)\n",
    "X_train_tw, X_test_tw, y_train_tw, y_test_tw = train_test_split(avg_tw, df, test_size=0.2)\n",
    "\n",
    "# Wiki\n",
    "avg_wiki = get_avg_vectors(tokenized_comments, glove_wiki_model, 300)\n",
    "X_train_wiki, X_test_wiki, y_train_wiki, y_test_wiki = train_test_split(avg_wiki, df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now train our models using the new embedding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_twitter_emotion = MLPClassifier(max_iter=10)\n",
    "mlp_twitter_emotion.fit(X_train_tw, y_train_tw['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_twitter_sentiment = MLPClassifier(max_iter=10)\n",
    "mlp_twitter_sentiment.fit(X_train_tw, y_train_tw['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_wiki_emotion = MLPClassifier(max_iter=10)\n",
    "mlp_wiki_emotion.fit(X_train_wiki, y_train_wiki['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_wiki_sentiment = MLPClassifier(max_iter=10)\n",
    "mlp_wiki_sentiment.fit(X_train_wiki, y_train_wiki['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict and send results to performance.txt.\n",
    "\n",
    "Note: if UndefinedMetricWarning shows, it simply means that our model never predicts certain labels (eg. may never predict a post as being labelled 'grief'. This can usually be fixed by increasing the number of iterations.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tw_emotion = mlp_twitter_emotion.predict(X_test_tw)\n",
    "y_pred_tw_sentiment = mlp_twitter_sentiment.predict(X_test_tw)\n",
    "y_pred_wiki_emotion = mlp_wiki_emotion.predict(X_test_wiki)\n",
    "y_pred_wiki_sentiment = mlp_wiki_sentiment.predict(X_test_wiki)\n",
    "\n",
    "with open('performance.txt', 'a') as f:\n",
    "    f.write('MLP emotion classifier: glove-twitter-200 embedding model\\n\\n')\n",
    "    f.write(classification_report(y_pred_tw_emotion, y_test_tw['emotion']))\n",
    "    f.write('\\n\\n')\n",
    "\n",
    "    f.write('MLP sentiment classifier: glove-twitter-200 embedding model\\n\\n')\n",
    "    f.write(classification_report(y_pred_tw_sentiment, y_test_tw['sentiment']))\n",
    "    f.write('\\n\\n')\n",
    "\n",
    "    f.write('MLP emotion classifier: glove-wiki-gigaword-300 embedding model\\n\\n')\n",
    "    f.write(classification_report(y_pred_wiki_emotion, y_test_wiki['emotion']))\n",
    "    f.write('\\n\\n')\n",
    "\n",
    "    f.write('MLP sentiment classifier: glove-wiki-gigaword-300 embedding model\\n\\n')\n",
    "    f.write(classification_report(y_pred_wiki_sentiment, y_test_wiki['sentiment']))\n",
    "    f.write('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "40373490c7673d06f4a43f8a8785636cc055897b683e6a5ffe207e45dab1f65c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
